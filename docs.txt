NodeJS is nothing is just a runtime which is used to run the javascript outside of the browser. So who does run the code if not the browser? The answer is V8 engine developed by Google. Where the javascript code will be parse and run in NodeJS. Before NodeJs this was completely impossible to access the file system. After NodeJS this has made javascript to use on server development for website. you can build fast, highly scalable and network applications.

*************Pros of NodeJS
NodeJS is single thread, event driven, non-blocking I/O model which makes it highly lightweight and efficient. 
It is perfect for building highly scalabe and fast apps.

NOTE: in node JS I/O means file accessing and networking like stuff.
**********Use Cases of NodeJS
1. API with databases behind it (preferably NoSQL like MongoDB)
2. Data Streaming apps such as Youtube
3. l-time chat applications
4. ver-side web applications
5. single language for entire stack


**NOTE**: DO NOT USE NODE JS if your server needs high end processing such as image processing, video conversion etc. (CPU intensive tasks). So its better you use RoR, PhP or Python
REPL: Read Eval Print loop


**********Checking global variables in terminal

type node and press enter

now press tab button once or twice

********Checking methods which we can apply on global variables
type any global variable and add . at the end and press tab once or twice


for example:

>String.    (after writting that press tab twice)


***************Modules in Javascript
with the help of node js we can things which we cannot do in the browser such as interacting with the files using file system.

const fs = require('fs');

//here we have imported our module in backend the require function has created an object which is stored in fs variable now we can apply bunch of methods on it.

const textIn = fs.readFileSync('./txt/input.txt', 'utf-8');
console.log('textIn:', textIn);

const textOut = `This is what we know about Avocado: ${textIn}. \nCreated on ${Date.now()}`;
fs.writeFileSync('./txt/output.txt', textOut);

console.log('File has been written!');

This is how we read and write files in JS synchronously.

A gentle reminder of async and sync javascript doe.
sync is a blocking code whereas async is a non blocking code.

Since we all know that NodeJs is made up on single thread paradigm model. which simply means that all the user who are accessing our application are using the single thread. If any of the user used a synchronous code that is blocking all the other users have to wait. In order to prevent this we use async code which also runs a callback function once the code is executed. In JS you will see there is a lot of callback functions.

Example:

const fs = require('fs');
const textIn = fs.readFile('./txt/input.txt', 'utf-8', (err,data)=>{console.log(data)};
console.log('textIn:', textIn);


***************Creating a server
In node JS a server can create by using http module so,
const http = require("http");

const server = http.createServer((req, res) => {
  console.log(req);
  res.end("Hello from the server");
});

// Here when ever the user sends the request to the server the above callback function is gonna run

Server.listen(8000, "127.0.0.1", () => {
  console.log("Listening to request on port 8000");
});

NOTE: port is nothing just a subaddress for the host that is localhost


************Routing in nodeJs

const http = require("http");
const url = require("url");

const server = http.createServer((req, res) => {
  console.log("URL: ", req.url);

  const pathName = req.url;
  if (pathName === "/" || pathName === "/overview") {
    res.end("This is an overview page");
  } else if (pathName === "/product") {
    res.end("This is a product page");
  } else {
    res.writeHead(404, {
        'Content-type': 'text/html',
        'my-own-header': 'This is my own custom header'
    }) 
    // this method is used to send back the status code and headers with a response. but important point to note that
    // the header must be set before sending the res.end response.
    res.end("<h1>404 ERROR, Couldn't found the page</h1>");
  }
});

server.listen(8000, "127.0.0.1", () => {
  console.log("Listening to request on port 8000");
});

// Headers are nothing they are just a piece of information which we send either as a req or res.
// we can have our custom headers as well. There are some general headers such as 'content-type'. This will tell the browser
// what type of content is gonna come as a response.


************APIs
while building APIs simply imagine that the VS code is a server and browser is a client. All responses would be shown to the client

*********Imp methods
req.url //is used to get the the whole url
url.parse(req.url, true) // this is used to get an object which contains all the information about the searching url which also contains the query object.

*************Creating custom module

module.exports = (temp, product) => {
    let output = temp.replace(/{%PRODUCTNAME%}/g, product.productName); // here g means global
    output = output.replace(/{%IMAGE%}/g, product.image); // here g means global
    output = output.replace(/{%PRICE%}/g, product.price); // here g means global
    output = output.replace(/{%FROM%}/g, product.from); // here g means global
    output = output.replace(/{%NUTRIENTS%}/g, product.nutrients); // here g means global
    output = output.replace(/{%QUANTITY%}/g, product.quantity); // here g means global
    output = output.replace(/{%DESCRIPTION%}/g, product.description); // here g means global
    output = output.replace(/{%ID%}/g, product.id); // here g means global
  
    if (!product.organic)
      output = output.replace(/{%NOT_ORGANIC%}/g, "not-organic"); // here g means global
    return output;
  };

// this is how you export you custom module

const replaceTemplate = require('./modules/replaceTemplate')

// And this is how you can import your custom made module


*************NPM
NPM stands for node package manager. Its a CLI registry for installing open source packages. It is one the largest package registry in the world.

***********Dev dependencies
These are the dependencies which are used only for development purposes. These are simply tools which are used while developing an application such as nodemon, module bundler, testing tool etc. Our application do not depend upon them. These dependencies are not included in production.
This is how you install a dev dependency 

>$ npm install nodemon --save-dev

**********Package versioning and updating

a.b.c

where,
a = major version (Huge new release. This may break changes. This may not work with the previous version or code)
b = minor version (new features but these features will not break changes. The new version would be back-ward compatible)
c = patch version (Bug fixes)

-----------

~a.b.c

here ~ this symbol means that we only want to change the patches. Like you open your code base after long time and run npm install it will not update your package to the latest version of the major change but it will only update the patch that is c in this case. It is very safe to use this ~ instead of * which means all versions

^a.b.c

In case of this ^ symbol you will be updated to the wanted or latest version of the app.


There is a command which is used to check the outdated ness of a package

npm outdated

this will give you the information about your package which is installed in your application. That what is its current version what is the accepted version and what is the latest version
-------------------------- Prettier custom configurations
create a file called .prettierrc
and change it like as below as I want to have single quote instead of double qoute for strings.
{
    "singleQuote": true
}


****************************************How web works behind the scenes
When user make a request from the browser by entering the url it contains three component

protocol://domain/resource

https://google.com/maps

In actual what we type that is URL is not the actual address of the server. The address of serve doesn't make sense in reading as its look something like

https://216.58.211:433

so if the url is not the actual address then how a browser is gonna reach our desired server? Here comes DNS (Domain name server) which is a special type of server provided by the ISP (Internet service provider). DNS server is exactly like a phone book.

when a client makes a request the url is send to DNS server where it is matched with the actual address and then the DNS server forward the request to the actual server and then server sends back the response. This whole cycle is called client server Architecture or Client server Request-Response model.


When our website is put on the internet TCP/IP (Transmission control protocol/ Internt Protocol) socket connection is established between client and a server. This connect is kept alive all the time when the data is transferring between the web server and client. These communication protocols actually defines some set of rule that how the data will move on internet.

HTTP is another protocol. Which allows the user to send request to the server and get response back from the server.
The difference between HTTP and HTTPs is that HTTPS is encrypted with TSL or SSL which are some more protocols.

HOW HTTP Request looks like

It has 3 components
Start line: HTTP method (GET,POST etc) + request target + http version
HTTP request headers: (Information)
Request Body: (This 3rd component will be only here if we are sending data to the server that is POST)


HOW HTTP Response looks like
1. Start line: http version + status code + status message
2. HTTP request headers: (Information, the diff. b/w the header of http res and http req is that in case of  http res these are the headers which are specified by the      backend developer) 
3. request Body: (This will specified by the backend developer which data is to send back to the client)

The html file is send back and get scanned by the browser to collect all resources to build the app and show to the client.


The job of TCP is to break the data in thousands of small chunks called packets before send the data. Once the data is reached to the destination it will reassemble all the packets into the original request or response. The main reason of following this protocol is to increase the speed of transfering data.
The loading of data would be much slower if we send the data as a single big chunk which is not a good idea.

Where as the job of the IP is to route the data over the data and to make sure that the data is arrived to the right address.



-----------------Static VS Dynamic 
Static files are simply those files are ready to be served. There is no work done on the server. There is no backend code. You may think that how can a website which is interactive and contains a JS file and still be a static site? Why not dynamic? The word used dynamic on front end is different from the word dynamic used on the backend.

In dynamic websites: there is database and an app like node JS is running on the server which is sending request to the Database and fetching data from database and filling the front end template and made the ready to serve file and then send to browser to display to the client. This whole process is called SSR server side rendering.
NEXTjs is an example of SSR

API-powered website: API website are same as dynamic website but the difference is that we send data to browser in the form of JSON data format. Not any CSS, HTML and JS file. This process is the building of APIs. 
The JSON data which was send from the backend is received on the front end by the frame works like react, angular and then it is rendered on the front end side. This is called consuming APIs. They are also called cliend side Rendering (CSR)
Node is best for making API-powered websites. we can make both kinds of websites with nodejs.

The huge advantage is of api-powered website is that as these are created in node or in any other languages can be consumed by other clients such as native mobile apps than just the browser.

in case of Dynamic SSR websites we cannot do this we can only run them in browser.


*****************NodeJS archtitecture behind the scenes
NodeJS do not only rely on V8 engine of the browser but also rely on some other stuff such as 
libuv (libuv is a multi-platform C library that provides support for asynchronous I/O based on event loops.)
http-parser (for parsing http request)
c-area (For DNS request stuff )
OpenSSL (For cryptography stuff)
zlib (For file compression)


here important point to not that v8 engine and libuv both are written in C++. Here nodeJs is also written in JS & C++ but the beauty is that nodeJS combines them all and provide us the access to C++ function with pure JS.


***************NODE PROCESS and THREADS

Node process is nothing but an instance of a program in execution on a computer
It is always and most important to remember that node always run in single thread. Not matter either there are thousand users or millions of users it is always gonna run in single thread.
This feature of Node makes it easier to block the code. So we always have to take care about the blocking of the code.

**************So what happens when a JS code is executed?
1. When the program is initialize all the top level code is executed first (the code Which is outside of any callback function), all required modules that our app are required and all callbacks are registerd. After that event loop finally starts running. (Event loop is a heart of nodeJS architecture as most of the code is running in event loop).
But there are some task which are too extensive to run in event loop which can block our code. This is the time where thread pool comes in. Which is just like event loop its a library provided by libuv to nodeJS to perform async I/O opertations and to manage event loop.
Libuv provides us 4 or more additional threads (we can configure upto 128 threads) but usually these 4 are enough. These threads combines and form a thread pool. So nodeJS autmatically offload heavy task to the thread pool such as file system APIs, cryptography, compression of files and DNS lookups to match the urls with real IP addresses.
2. All the code which is not the top level code is gonna run in event loop (the code which is inside the callback function is called non-top-level code).

So in short nodeJS do orchestration. It receive the callbacks, execute them in event loop and in case of heavy task it send it to the thread pool.

EVENT LOOP  IN DEPTH:
Event loop has many phases. And each phase has a callback queue.

1st phase Expiration timer callbacks : This phase talks care about the expiration of callbacks (setTimeOut()). In callback queue all code runs behind each other until the node make sure that there is no callback which is left in the callback queue. Once this phase completed node moves to the 2nd phase

2nd phase I/O polling and callbacks: This phase handles stuff related to I/O such as networking and  file accessing. 99% of our code is gonna execute in this phase.

3rd phase setImmediate callbacks: In this phase node runs those callbacks which are supposed to immediately execute right after the execution of first two phases. This phase is basically an advance topic and can be useful in some cases.

4th Close callbacks: This phase includes the callbacks which are supposed to be executed on closing such as shutdown of the websocket etc. 

NOTE: Beside these 4 callback queue there two more callbacks such as PROCESS.NEXTTICK() queue and MICROTASKS queue which are used to resolve promises.
Important point o note that these two special queue do not have to wait to complete the loop of all 4 above mentioned callbacks. These queues get executed after all 4 callbacks each time. Here PROCESS.NEXTTICK() queue  is used for many advance cases.



************WHY DO WE NEED EVENT LOOP?
The answer is simple the we need event loop because nodeJS is single thread no matter how many users are there. So there is a danger of blocking of code thats why we need event loop which makes it more light weight and scalable.

NOTE: ITS YOUR RESPONSIBILTY TO MAKE YOUR CODE NON-BLOCKING.
THIS IS HOW YOU CAN PREVENT YOUR CODE NOT TO BLOCK:

1. Dont use synchronous versions of fcuntions in the fs, crpyto and zlib modules inyour callback functions.
2. Don't perform complex claculations (loops inside loops)
3. Be careful with JSON in large objects.
4. Don't use too complex regular expressions


************EVENT LOOP IN ACTION

const fs = require("fs");

setTimeout(() => console.log("Timer 1 finish"), 0);
setImmediate(() => console.log("Immediate 1 finished"));

fs.readFile("test-file.txt", () => {
    console.log("I/O finished");
    setTimeout(() => console.log("Timer 2 finish"), 0);
    setTimeout(() => console.log("Timer 3 finish"), 3000);
    setImmediate(() => console.log("Immediate 2 finished"));
    process.nextTick(()=> console.log('Process.nextTick'))
});


console.log('Hello from the top level code');

// Ouput: 
Hello from the top level code
Timer 1 finish
Immediate 1 finished
I/O finished
Process.nextTick
Immediate 2 finished
Timer 2 finish
Timer 3 finish


Explanation:
As expected our top level code which is outside of any callback function get executed first after that event loop looked for the callbacks. When ever there is a settimeout function event loop will wait for the polling phase until the timer is expired. Therefore, immediate function ran after the set timeout function.
the important point to note here is that process.nextTick get executed before the immediate and setTimeout The reason is that process.nextTick is a part of microtasks queue not callback queue. And we know that microTasks queue runs after each phase out of all 4 phases. It donot run after all 4 phases of event loop to complete. It will be check every time when each of the phase of event loop will be completed.


Example 3:
const fs = require("fs");
const crypto = require("crypto");
const start = Date.now()

setTimeout(() => console.log("Timer 1 finish"), 0);
setImmediate(() => console.log("Immediate 1 finished"));

fs.readFile("test-file.txt", () => {
  console.log("I/O finished");
  setTimeout(() => console.log("Timer 2 finish"), 0);
  setTimeout(() => console.log("Timer 3 finish"), 3000);
  setImmediate(() => console.log("Immediate 2 finished"));
  process.nextTick(() => console.log("Process.nextTick"));
  console.log("I/O 2nd finished");

  crypto.pbkdf2('password','salt', 100000, 1024, 'sha512', ()=>{
    console.log(Date.now() - start,"Password encrypted");
  })
});

console.log("Hello from the top level code");


// output
Hello from the top level code
Timer 1 finish
Immediate 1 finished
I/O finished
I/O 2nd finished
Process.nextTick
Immediate 2 finished
Timer 2 finish
2057 Password encrypted
Timer 3 finish



// Example 4: Where we will use synchronous version of the code. Here
const fs = require("fs");
const crypto = require("crypto");
const start = Date.now()
process.env.UV_THREADPOOL_SIZE = 1 //here we can manage the number of threads in thread pool. 

setTimeout(() => console.log("Timer 1 finish"), 0);
setImmediate(() => console.log("Immediate 1 finished"));

fs.readFile("test-file.txt", () => {
  console.log("I/O finished");
  setTimeout(() => console.log("Timer 2 finish"), 0);
  setTimeout(() => console.log("Timer 3 finish"), 3000);
  setImmediate(() => console.log("Immediate 2 finished"));
  process.nextTick(() => console.log("Process.nextTick"));
  console.log("I/O 2nd finished");

  crypto.pbkdf2Sync('password','salt', 100000, 1024, 'sha512', ()=>{
    console.log(Date.now() - start,"Password encrypted");
  })
  crypto.pbkdf2Sync('password','salt', 100000, 1024, 'sha512', ()=>{
    console.log(Date.now() - start,"Password encrypted");
  })
  crypto.pbkdf2Sync('password','salt', 100000, 1024, 'sha512', ()=>{
    console.log(Date.now() - start,"Password encrypted");
  })
  crypto.pbkdf2Sync('password','salt', 100000, 1024, 'sha512', ()=>{
    console.log(Date.now() - start,"Password encrypted");
  })
});

console.log("Hello from the top level code");

//output

here the output will be line by line as the code is executing synchronously last four lines of the output will not show until the password is not encrypted this is happening because we are using 3rd party module in callback this means out encryption was not happening inside event loop. While the rest of the code was. The compiler will only pick the code from the event loop once the code in thread pool has completed. As the code in thread pool was not asynchronous therefore compiler had to wait.


Hello from the top level code
Timer 1 finish
Immediate 1 finished
I/O finished
I/O 2nd finished
1826 Password encrypted
3597 Password encrypted
5318 Password encrypted
7070 Password encrypted
Process.nextTick
Immediate 2 finished
Timer 2 finish
Timer 3 finish

// EVENT AND EVENT-DRIVEN ARCHITECTURE:

In NodeJS everything is event driven. 
There is an emitter and there is a listener.

For example

server.on('request', callback)

here whenever user make the request the server.on emit the event and here 'request' will listen it. This is how emitting and listening the event cycle goes.


***********STREAMS
Streams is also one of the fundamental concept in CS. Its basically a concept in which we process (read and write) the data by pieces instead of processing the whole data once.
Perfect application of this concept is in Youtube and netflix where the videos are streamed as their piece of data is downloaded. Instead of waiting for the whole file to download and play streams plays as the data is downloading.

streams are perfect for handling large volumes
TYPES OF STREAMS
In NodeJS there are 4 types of streams
1. Readable Streams: Streams from which we can consume data such as http requests, fs read streams, pipe(), read() functions.
2. Writable Streams: (most imp) Streams from which we can write data such as http requests, fs read streams, write(), end() functions.
3. Duplex Streams: Streams that are both readable and writable such as web sockets.
4. Transform Streams: Streams that transform data as it is written or read.


***********STREAMS IN ACTION
const fs = require('fs');
const server = require('http').createServer();

server.on('request', (req, res) => {
  // sol1 : without stream
  fs.readFile("test-file.txt", (err, data) => {
    if (err) console.log(errr);
    res.end(data);
  });

  // sol2: Stream

  const readable = fs.createReadStream('test-file.txt');
  
  readable.on('data', (chunk) => {
    res.write(chunk);
  });
  readable.on('end', () => {
      res.end();
    });
    readable.on('error', (error) => {
        console.log(error);
        res.statusCode = 500;
        res.end('File not found!');
      });
      
  //sol3: 
    const readable = fs.createReadStream('test-file.txt');
    readable.pipe(res)
    // readableSource.pipe(writeableDestination)


});

server.listen(8000, '127.0.0.1', () => {
  console.log('Listening...');
});


EXPLANATION: Here in this example we are trying to read a large txt file and send it as a response to the client on the browser. The solution 1 is the worst solution of sending and reading such large text file as this will eventually make your app to crash. 

In solution two we are reading data in the form of chunk by making the data a readable stream. This solution is good but there is special case in which reading the data from the file is fast but sending response is not as faster as we are reading the data. This situation is called back pressure. In order to avoid this we just have to you use pipe method on our readableSoure that is text file in this case. This is solution 3 which is best for this case.


///////////////////// HOW REQUIRE MODULE WORKS	
IN node js as we all know if we want to export any module we simple do

module.exports = yourFunctionName;

we can also do:

module.exports = anyFunction

we can also do:

exports.anyName = () => {}

what is Caching
// in path file
console.log("I am happpy")
module.exports = () => console.log("I am sad");


// In other file
require('./path)()
require('./path)()
require('./path)()

//output
I am happpy
I am sad
I am sad
I am sad


// the  reason by I am happy console only 1 time due to caching. Node stores in somewhere in memory and console only once no matter how many time it is get imported. Where as I am sad was console 3 times because it was calling by a function 3 times.



****************************Express
Express is a NodeJS frame work which means it is build on the top of NodeJs. It includes complex routing, easier handling of request and responses, middleware, SSR etc. It makes easier for us to organize our applicaiton in MVC architecture.
Express automically send some pre-defined headers. We do not manually defined the headers in some cases.

************Postman
Postman is a tool which is used for API testing. It works like browser (Client side) but it do not render HTML.


*************Express Natrous Project

One thing that I would like to mention before making project in Node js that is "Web is all about sending request and responses"

Standard is that we firt make an app.js file where we do all our configuration like creating app in express, defining routes and ports and listening to the server.

************Setting UP express and basic routing
// basic configuration in app.js

const express = require('express')

const app = express()

app.get('/', (req,res)=>{
    res.status(200).send('Hello from server side!')
})

const port = 3000;
app.listen(port,()=>{
    console.log(`Server is running on port ${port}`);
})

NOTE: Since its a good practice and easy to send json file so instead of using res.send we will use res.json({key:value}) as below:

const express = require('express');

const app = express();

app.get('/', (req, res) => {
  res.status(200).json({ message: 'Hello from server side!', app: 'Natours' });
});
app.post('/', (req, res) => {
  res.status(200).json({ message: 'You can post data to this endpoint', app: 'Natours' });
});

const port = 3000;
app.listen(port, () => {
  console.log(`Server is running on port ${port}`);
});




Always remember, you can read data from Client side using endpoint/URL defined with GET method. Similarly, YOu can send data from Client side to the endpoint/URL which is defined with POST method.


***********REST API architecture
REST stands for Representaion States Transfer, It is basically a way of building API logic so they are easy to consume for the user. In order to build APIs following the principle of REST architecture we have to follow some rules:
1. Separate API into logical resources.
2. Expose/Show structured, resource-based URLs
3. Use HTTP methods
4. Send data as JSON format
5. Must be stateless

Let understand all 5 principles one by one:
1. Separate API into logical resources: Here resource means any kind of information such as reviews, tours etc. First separate all the information in logical way. Here logical means name shoudl make sense.

2. Expose structured & 3. Use HTTP methods, resource-based URLs: The address of our URLs should be resource based and do not include any action in their name such as /getNewTour, /addNewTour, /deleteTour, /updateTour etc. Don't do this. It should not be look like this
so instead of this our URLs should look like this:

GET   /tours  (for getting the tours)
POST  /tours   (for adding new tours)
DELETE /tours   (for deleting the tours)
PUT or PATCH /tours    (for updating the tours the difference b/w put and patch is that put is to update the entire object and patch is used to update the piece of an object)

here you have notice that our endpoints are same put our HTTP methods are different. Our URL contains only names not actions. Our actions are defined by our http method.

in case of getting or approaching to a specifi user or a specific tour we have to get their by a unique id or unique information. for example:
GET   /tours/46  (for getting the tour having id 46)

4. Send data as JSON format:
JSON is very lightweight to transfer information. In JSON all keys are strings. Values can be anything such as strings, number, boolean etc.
The good practice is that we use Jsend. In this format we use a status and wrap all data in data object

{
"status":"succcess",
"data": {
	"id":5,
	"name":"John",
	}
}

5. API Must be stateless
Means all state must be handled on client side. This means that each request must contain all the necessary information to process a certain request. The server should not have to remember previous requests on the server.

For example:
If we are on currently page 5 and we have made an API URL that is /nextPage

so in order to go to page 6 server shoudl remember current page as nextPage = currentPage + 1. This is bad. We should avoid it in REST architecture. Instead you should simply pass a number
/page/6


*****************Lets start building APIs

I will just mention here best practices and things which are important only

app.get('/api/v1/tours', (req, res) => {
  res.status(200).json({
    status: 'success',
    results: tours.length,
    data: {
      tours: tours,
    },
  });
});

here making APIs URL with /api/v1/tours
here v1 is the version of the api. It is a good practice to add version of your API in URL as it is important while making changes to it to make version 2.

*******Handling POST request
app.post('/api/v1/tours', (req, res) => {
	console.log(req.body);
    res.status(200).send('Done') // You always have to send response back to complete req-res cycle
})

here in post request the data is send from the client to the server. So that data should be available in req parameter right? but Express does not put that body data on the req parameter. So in order to have that availble we use a simple middleware on top of the express app. (Middleware is simply a function that modifies the incoming request data. It is called middleware as it stands between the request and the response)

const app = express();
app.use(express.json())


****Sending data from the postman (Client side) to the server
Select HTTP POST  method and paste your end point and go to body tab and select raw and JSON
now write you JSON object
{
    "name": "Test Tour",
    "duration": 10,
    "difficulty": "easy"
}



**JavaScript**
const newTour = Object.assign({ id: newId }, req.body);

// This is how you merge two objects in javascript.



***Saving data to our finctional database (folder or .json file)

app.post('/api/v1/tours', (req, res) => {
  console.log(req.body);
  const newId = tours[tours.length - 1].id - 1;
  const newTour = Object.assign({ id: newId }, req.body);
  tours.push(newTour);

  
  fs.writeFile(`${__dirname}/dev-data/data/tours-simple.json`, JSON.stringify(tours), err => {
    res.status(201).json({
        status: 'success',
        data : {
            tour : newTour
        }
    })

  })
});


// Here status 201 means created

***********Responding to URL parameters
If you want to add a variable in your url this is how you can do that

app.get('/api/v1/tours/:id', (req, res) => {
    console.log(req.params);
  res.status(200).json({
    status: 'success',
  });
});

// so here If you would access this endpoint with any id after /api/v1/tours/ such as /api/v1/tours/25

you will get

{ id: '25' }

you can also do something like this 
app.get('/api/v1/tours/:id', (req, res) => {
  console.log(req.params);
  const id = req.params.id * 1;
  const tour = tours.find((el) => el.id === id);
  res.status(200).json({
    status: 'success',
    data: {
      tour: tour,   
    },
  });
});


So on accessing 127.0.0.1:3000/api/v1/tours/69/68/67
you can get
{ id: '69', x: '68', y: '67' }


**JS: const id = req.params.id * 1; //This is how you convert a string into a number. Type coersion JS automatically converts a string number into a number one multiplying it by any number. Here find method loop over each element and return a new array wo satisfay the logic in the callback function.

*************Handling patch request
app.patch('/api/v1/tours/:id', (req, res) => {
    if (req.params.id *1 > tours.length) {
        return res.status(404).json({
            status: 'fail',
            message: 'Invalid ID'
        })
    }
  res.status(200).json({
    status: 'success',
    data: {
      tour: '<update tour here>',
    },
  });
});

This is how we deal with a basic patch request.


****************Handling Delete request
app.patch('/api/v1/tours/:id', (req, res) => {
    if (req.params.id *1 > tours.length) {
        return res.status(404).json({
            status: 'fail',
            message: 'Invalid ID'
        })
    }
  res.status(204).json({
    status: 'success',
    data: null,
  });
});

This is how we deal with a basic delete request.

**************Cleaning the code

// separate all login of all HTTP methods into a separate function and then call them respectively.

app.get('/api/v1/tours', getAllTours);
app.get('/api/v1/tours/:id', getTour);
app.post('/api/v1/tours', createTour);
app.patch('/api/v1/tours/:id', updateTour);
app.delete('/api/v1/tours/:id', deleteTour);

where getAllTours is:
const getAllTours = (req, res) => {
  res.status(200).json({
    status: 'success',
    results: tours.length,
    data: {
      tours: tours,
    },
  });
};

and so on of rest of the funtions

*************Cleaning the code part 2

now in order to overcome the repeatability of routes we can do something like this

app.route('/api/v1/tours').get(getAllTours).post(createTour);
app
  .route('/api/v1/tours/:id')
  .get(getTour)
  .patch(updateTour)
  .delete(deleteTour);

// This is exactly same as:

// app.get('/api/v1/tours', getAllTours);
// app.get('/api/v1/tours/:id', getTour);
// app.post('/api/v1/tours', createTour);
// app.patch('/api/v1/tours/:id', updateTour);
// app.delete('/api/v1/tours/:id', deleteTour);


***************Middleware and Request Response cycle

Middleware is nothing its simple a req-res Obj or you can say its a function which get executed in between sending the response and receiving the request.
In express everthing is middleware. Even routes functions are middleware. All middleware in our app is called middleware stack.

The order of middleware in a middleware stack is depent on the order they are declared. The one who is defined earlier will get executed first. So the order of the code matters a lot in Express. You have noticed in many of the code that next() function is executed at the end of every middleware. In all middleware functions we have access to next() function just same as we have access to req, res functions in HTTP methods.

So when the next() function is executed we call the next middleware with the exact same req-res obj. Its like pipeline through which our receiving request obj goes through. Moreover, in the last middleware we do not call next function we actually send response back to client.

************Creating our own Middleware


app.use((req, res, next) => {
  console.log('Hello from the middleware!');
  next();
});


// This is the most basic middleware function which will run whenever we will make an API request on any route. This is because we didnt specified any route and defined this middlerware at the top of all routes thats why all routes after the declaration of this middleware will call this middleware on making request. As we know that in middleware the order of it declaration matters a lot. If we define it at the end after the all routes. Then this was not gonna call on any api request.

**EXP2**
app.use((req, res, next) => {
  req.requestTime = new Date().toISOString();
  next();
});

const getAllTours = (req, res) => {
  console.log(req.requestTime);
  res.status(200).json({
    status: 'success',
    requestAt: req.requestTime,
    results: tours.length,
    data: {
      tours: tours,
    },
  });
};


*************Using 3rd party middleware

npm install morgan
HTTP request logger middleware for node.js. Its is a very simple middlerware. On making any HTTP request this will give you a log of that request. Here log includes, HTTP Method, API endpoint,status code, time it took to send back response, and size of the response in bytes.

Here is an example of morgan log:  GET /api/v1/tours 200 4.679 ms - 8680

const morgan = require('morgan');
app.use(morgan('dev'));

//This Morgan middleware just like normal middleware returns a function (req, res, next)




***************Creating Routes for users
app
   .route('/api/v1/users')
   .get(getAllUsers)
   .post(createUser);
app
  .route('/api/v1/users/:id')
  .get(getUser)
  .patch(updateUser)
  .delete(deleteUser);


****************Creating and mounting multiple routes

// Routes for tours
app.route('/api/v1/tours').get(getAllTours).post(createTour);
app
  .route('/api/v1/tours/:id')
  .get(getTour)
  .patch(updateTour)
  .delete(deleteTour);

//Routes for users
app.route('/api/v1/users').get(getAllUsers).post(createUser);
app
  .route('/api/v1/users/:id')
  .get(getUser)
  .patch(updateUser)
  .delete(deleteUser);

// Here we have to note that till this point all our routes, controller for both users and tours are in the same file. Now its time to move them in a separate file as it is a good practice and will allow us to manage and scale our code. But before doing that we have to define separate route for users and tours. Here in this case both are sunning on same  route that is app routs. So in order to separate it lets use a middleware for creating separate routes


This is how you do that:

const tourRouter = express.Router();
app.use('/api/v1/tours', tourRouter); //This is basically called Mouting the router
tourRouter.route('/').get(getAllTours).post(createTour);
tourRouter.route('/:id').get(getTour).patch(updateTour).delete(deleteTour);

here we are using middlerware for a specific route that is /api/v1/tours now this will become your parent route.


************File structuring

So create a routes folder in the root directory
and create two files:
1. tourRoutes.js
2. userRoutes.js

Now put the respective route code in respective files except middlewares. keep your middleware in your app.js file and remember that it is a standard.
Moreover in tourRoutes.js we do no export module with tourRouter we will export module with Router name as
const Router = express.Router();
module.exports = Router;

same for userRoutes.js


now create a controller folder and create two new files called

1. tourController.js
2. userController.js

and paste all your controller functions here and export them all as

exports.myFunction => {}
exports.myFunction2 => {}

and so on

const controllerFunctions = require('./path');

// how to use?

controllerFunction.myFunction
controllerFunction.myFunction2
// This is how you use these functions in other files


Create a server.js on  the level of app.js and run server there

// In app.js
.. rest of the code
module.exports = app;


// In server.js
const app = require('./app')
const port = 3000;
app.listen(port, () => {
  console.log(`Server is running on port ${port}`);
});



Now lets summarize our file structure

we have

1. server.js (Our server is running here)
2. app.js (All configurations such as middlewares, mounting routes etc.)
3. routes Folder (All routes/subapp)
4. Controller Folder (All logic or handler function of routes are here)


Always follow this standard

Now to summarise let me show you the code in each file

// 1. In Server.js

const app = require('./app')
const port = 3000;
app.listen(port, () => {
  console.log(`Server is running on port ${port}`);
});


// 2. app.js

const express = require('express');
const morgan = require('morgan');
const tourRouter = require('./routes/tourRoutes')
const userRouter = require('./routes/userRoutes')

const app = express();

// middlewares
app.use(morgan('dev'));

app.use(express.json());

app.use((req, res, next) => {
  req.requestTime = new Date().toISOString();
  next();
});

// Mounting the routes
app.use('/api/v1/tours', tourRouter);
app.use('/api/v1/users', userRouter);

module.exports = app;


// 3. In Route Folder
//In tourRoute.js

const express = require('express');
const tourController = require('../controllers/tourController');
const router = express.Router();

router.route('/')
  .get(tourController.getAllTours)
  .post(tourController.createTour);
router.route('/:id')
  .get(tourController.getTour)
  .patch(tourController.updateTour)
  .delete(tourController.deleteTour);

module.exports = router;

//In userRoute.js

const express = require('express');
const userController = require('../controllers/userController');
const router = express.Router(); //Its a convention to call it router instead of userRouter

router.route('/')
  .get(userController.getAllUsers)
  .post(userController.createUser);
router.route('/:id')
  .get(userController.getUser)
  .patch(userController.updateUser)
  .delete(userController.deleteUser);

module.exports = router;


// 4. In Controller folder
// tourController.js
const fs = require('fs');
const tours = JSON.parse(
  fs.readFileSync(`${__dirname}/../dev-data/data/tours-simple.json`)
);

exports.getAllTours = (req, res) => {
  console.log(req.requestTime);
  res.status(200).json({
    status: 'success',
    requestAt: req.requestTime,
    results: tours.length,
    data: {
      tours: tours,
    },
  });
};

exports.getTour = (req, res) => {
  console.log(req.params);
  const id = req.params.id * 1;

  const tour = tours.find((el) => el.id === id);
  if (!tour) {
    return res.status(404).json({
      status: 'fail',
      message: 'Invalid ID',
    });
  }
  res.status(200).json({
    status: 'success',
    data: {
      tour: tour,
    },
  });
};

exports.createTour = (req, res) => {
  console.log(req.body);
  const newId = tours[tours.length - 1].id + 1;
  const newTour = Object.assign({ id: newId }, req.body);
  tours.push(newTour);

  fs.writeFile(
    `${__dirname}/dev-data/data/tours-simple.json`,
    JSON.stringify(tours),
    (err) => {
      res.status(201).json({
        status: 'success',
        data: {
          tour: newTour,
        },
      });
    }
  );
};

exports.updateTour = (req, res) => {
  if (req.params.id * 1 > tours.length) {
    return res.status(404).json({
      status: 'fail',
      message: 'Invalid ID',
    });
  }
  res.status(200).json({
    status: 'success',
    data: {
      tour: '<update tour here>',
    },
  });
};

exports.deleteTour = (req, res) => {
  if (req.params.id * 1 > tours.length) {
    return res.status(204).json({
      status: 'fail',
      message: 'Invalid ID',
    });
  }

  res.status(204).json({
    status: 'success',
    data: null,
  });
};
	

// In userController.js

exports.getAllUsers = (req, res) => {
    res.status(500).json({
      status: 'error',
      message: 'This route is not yet defined',
    });
  };
  exports.createUser = (req, res) => {
    res.status(500).json({
      status: 'error',
      message: 'This route is not yet defined',
    });
  };
  exports.getUser = (req, res) => {
    res.status(500).json({
      status: 'error',
      message: 'This route is not yet defined',
    });
  };
  exports.updateUser = (req, res) => {
    res.status(500).json({
      status: 'error',
      message: 'This route is not yet defined',
    });
  };
  exports.deleteUser = (req, res) => {
    res.status(500).json({
      status: 'error',
      message: 'This route is not yet defined',
    });
  };


**************Param middleware function

Param middle ware is a middleware which is run only for certain parameters in our URL. Here in our case we have id in our URL.
Since we have created our routes folder now
// In tourRoute.js

const router = express.Router();
router.param('id',(req, res, next, val)=>{
 console.log(`The Value of Id is: ${val}`);
  if (req.params.id * 1 > tours.length) {
    return res.status(404).json({
      status: 'fail',
      message: 'Invalid ID',
    });
  }
  next();
}


This req.param takes two argument one is our string which is in the URL (In our case its Id it will not work if we miss spelled Id). The second argument is callback function. The val argument in callback will have access to the value of id which the user is putting in the URL. 

In our app we are using this middleware for checking the id whether its valid or not. This middleware will run when the a url with any id will be called. 
It is standar to define the logic of callback function in controller function.

const tourController = require('../controllers/tourController');
router.param('id', tourController.checkID);



We are using middlewares instead of simple functions the reason behind this fact is that its a philosophy of express to use middlewares as much as we can.


*************Chaing middleware

One thing I would like to clear is that in our controller.js getTour, createTour all these functions are also middlewares.


Okay so this is how you chain or connect your middlware.

// In tourRoute.js
const express = require('express');
const tourController = require('../controllers/tourController');
const router = express.Router();

router.param('id', tourController.checkID);

router.route('/')
  .get(tourController.getAllTours)
  .post(tourController.checkBody, tourController.createTour); //Here checkBody is our middleware
router.route('/:id')
  .get(tourController.getTour)
  .patch(tourController.updateTour)
  .delete(tourController.deleteTour);

module.exports = router;

// Here syntax router.route.post(middlware, 2nd Middlware)
router.route.post(tourController.checkBody, tourController.createTour); //Here checkBody is our middleware which is responsible for checking name and price in the incoming data from the user before creating the new user.
remember that in our controller.js getTour, createTour all these functions are also middlewares.

// In tourController.js
exports.checkBody = (req, res, next) => {
  if (!req.body.name || !req.body.price) {
    return res.status(400).json({
      status: 'fail',
      message: 'Missing Name or price',
    });
  }
  next();
};

// Here if the confition is true then it will send back the response and will complete the req-res cycle. In case of false confition code inside if condition will not run and it will call the next() to call the next middleware that is createTour in this case.



*****************Accessing static files from our local machine using a new middleware

app.use(express.static(`${__dirname}/public`));


now go to the browser
http://127.0.0.1:3000/overview.html

or

http://127.0.0.1:3000/filename


*******Environmental variable
how to check in which environment we are currently working in


console.log(app.get('env'));

or

console.log(process.env) //process is a global core module in node js

In terminal if you want to set your env you can do this

> NODE_ENV=development npm run server.js

once the development is completed change it to production.. But if there are several env variables then its not a  good idea to set them in terminal so instead of doing this make a configuration file called config.env

**** Connecting .env file

npm install dotenv

// In server.js
const dotenv = require('dotenv');
dotenv.config({path: './config.env'})
define these two line on very top of your file

console.log(process.env); // To confirm the connection of env variables


***************ES lint

ES lint is basically a program which continuously scans our code for errors and bad practices. We use Prittier but we will also configure it with our es lint to highlight the errors. ES lint is for improve the quality of code.

Install ES lint and prettier extension in vscode

then 
$ npm install eslint prettier eslint-config-prettier eslint-plugin-prettier eslint-config-airbnb eslint-plugin-node eslint-plugin-import eslint-plugin-jsx-a11y eslint-plugin-react --save-dev



// In .eslintrc.json
{
  "extends": ["airbnb", "prettier", "plugin:node/recommended"],
  "plugins": ["prettier"],
  "rules": {
    "prettier/prettier": [
      "error",
      {
        "endOfLine": "auto"
      }
    ],
    "spaced-comment": "off",
    "no-console": "warn",
    "consistent-return": "off",
    "func-names": "off",
    "object-shorthand": "off",
    "no-process-exit": "off",
    "no-param-reassign": "off",
    "no-return-await": "off",
    "no-underscore-dangle": "off",
    "class-methods-use-this": "off",
    "prefer-destructuring": ["error", { "object": true, "array": false }],
    "no-unused-vars": ["error", { "argsIgnorePattern": "req|res|next|val" }]
  }
}


// In .prettierrc

{
  "singleQuote": true
}



************************MongoDB
its a NoSql database.
In Mongo DB each database can have more than once collection. 
Collections are like tables. And each collection contains document. 
By documents you can say Rows. Each row would be for post, user, reviews etc.
The good thing is that Document (rows) have JOSN like format but it is called BSON (Here all values will have some data type such as boolean, string, etc.)


Document based: MongoDB is a document based database it stores data in the form of document instead of rows as in traditional databases.
Scalabilty: Very easy to distribute data across multiple machine as your user and amount of data grows.
Flexible: No document data Schema required so each document can have different number and types of fields.

In relational data bases the data is always normalise.

In BSON:

1. maximum size of each document is 16MB
2. Each document has a unique id which act as a primary key for each document.


**********Installing mongoDB

Go to mongoDB official website --> Products --> MongoDB Community Server --> Download

Dont forget to create data and db folder inside C

Now arfter installing  the setup go to c drive --> program files --> mongoDB--> server --> 7.0 --> bin 

and copy its path 

now go to environemental variables of your windows and add this path there.
After adding this 

open your powershell or cmd

**********How to run local MongoDB server from cmd or powershell and how to connet it with DB
open your powershell or cmd

> mongod.exe

and now open another terminal and run > mongos.exe

************Connecting to a local database with cmd or powershell
open cmd and run

> mongosh.exe

> use databaseName
// here use commnand is used to switched b/w db if db doesnt exist it will create that automatically

Since we know that in mongoDB every document (row) is inside the a collection (table) so this means we first have to create collections then documents

** Adding data into database

>db.tours.insertOne({name:"The Forest Hiker", price: 297, rating: 4.7})
syntax: db.collectionName.function(data in BSON format)

insertOne is used to insert one document and insertMany is used to insert more than one documents

*** Checking the created collection
>db.tours.find()

** checking all databases we created
> Show dbs

*** checking all collections

> show collections

******Quiting the mongoshell

> quit()


************Inserting multiple documents in single collection
>  db.tours.insertMany([{name: "The Sea Explorer", price: 497, rating: 4.8}, {name: "The Snow Adventure", price:997, rating: 4.9, difficulty: "easy"}])

This is how you enter multiple document in a single collection. 
**NOTE**: Always remember we are entering more than one document in the form of arrays. and Mongo DB understand double quote only.

*************Finding a specific object or document**************
> db.tours.find({name: "The Snow Adventure"})

MongoDb is case sensitive so incase of wrong spelling or case sensitive mistake it will show nothing.

> db.tours.find({price: {$lt:500}})

here we are finding objects having price less than 500. Here $ sign means mongo operator. You write your expressions in curly brackets {}
and same case goes for greater than operator you use {$gt:500} 

lt = less than
gt = greater than
lte= less than equal
gte = greater than equal


*********Using AND Operator
> db.tours.find({ price: {$lt:500}, rating: {$gte:4.8} })

Here comman is acting as AND operator. It is by default.

************Using OR operator

> db.tours.find({$or: [{price:{$lt:500} },{rating: {gte:4.8} }] })
 This is how you find objects in mongoDB using OR operator.

>db.tours.find({$or: [{price:997 },{rating: {gte:800} }] }, {name:1})

Here {name:1} means name true. Means The output will include only name field.

**********Updating the data/document

> db.tours.updateOne({name: "The Snow Adventure"}, {$set: {price: 597} })

syntax:  db.tours.updateOne(filter Object, {$set: {property:value} })

here filter object means the data with the help of you will select your object.


*********Adding new field in the existing document using updatingMany

> db.tours.updateMany({price: {$gt:500},rating:{$gte:4.8}}, {$set: {premium: true}})

by using this {price: {$gt:500},rating:{$gte:4.8}} we are selecting multple objects in between the given range and then the second argument is here to set the value.

**************Delete Data

>db.tours.deleteOne({price:497})

>db.tours.deleteMany({rating:{$lt:4.8}}) 
This is for deleting all objects have rating less than 4.8

>db.tours.deleteMany({})


************Using MongoDB Compass

Simply open your MongoDB compass and click on new connection and wihtout filling anything click on connect button
make sure your Mongod.exe server is running on backend in cmd or powershell.

you can use above queries in mongoDB compass filter field

*********Hosting a database

While developing apps we do not use actual local data bases for our use instead we host our remote database on as service called Atlas. Which is owned my the same company who own MongoDB.
Cluster is basically like an instance of our database.

Simply go to mongo login and login your account create a new project and add user and add IP address

Now to connect you will get a connection URL like mongodb+srv://<USERNAME>:<PASSWORD>@clustername.mongodb.net/test



****************Getting access to remote Database using CMD
To access a MongoDB Atlas database from your Windows Command Prompt, you can use the `mongosh` utility, which is the MongoDB Shell. Here are the steps to connect to your remote MongoDB Atlas database:

1. Open your Windows Command Prompt:
   - Press `Win + R`, type `cmd`, and press Enter.

2. Navigate to the directory where `mongosh.exe` is located if it's not in your system's PATH:
   - Use the `cd` command to change the directory. For example, if `mongosh.exe` is in the "C:\Program Files\MongoDB\Tools\100\bin" directory, you can navigate to it using:
     ```
     cd "C:\Program Files\MongoDB\Tools\100\bin"
     ```

3. Now, you can connect to your MongoDB Atlas cluster using the following command:
   ```
   mongosh "mongodb+srv://<USERNAME>:<PASSWORD>@clustername.mongodb.net/test" --authenticationDatabase admin
   ```
   Replace `<USERNAME>` and `<PASSWORD>` with your MongoDB Atlas cluster username and password. Also, replace `clustername` with the name of your MongoDB Atlas cluster.

4. Press Enter, and `mongosh` will connect to your MongoDB Atlas cluster.

For example, if your MongoDB Atlas username is "myuser," your password is "mypassword," and your cluster name is "mycluster," the command would look like this:

```shell
mongosh "mongodb+srv://myuser:mypassword@mycluster.mongodb.net/test" --authenticationDatabase admin
```

After running this command, you should be connected to your MongoDB Atlas cluster and can start interacting with your remote database.

OR simply get the link of your database that you put into your mongoDB compass

mongosh "mongodb+srv://username:<Password>@cluster0.vsioz83.mongodb.net/<DatabaseName>?retryWrites=true&w=majority"


***************In Summary of MongoDB

There are two servers one is local that is on your computer and other one is remote that is on Atlas
To get access to your local server you simply have to run mongod.exe in your terminal (remember you have added the path of bin directory of mongoDB in your windows environmental variables)
After running this mongod.exe you have created a local server in your PC. To get access to this locally created Database you simply have to open another terminal and run mongosh.exe
Congrats. You are done!


For Remote database: You first have to host your database to remote server that is Atlas. Simple go to mongoDB Atlas login and create database there and get its URL
Now open your terminal and run mongosh "mongodb+srv://<USERNAME>:<PASSWORD>@clustername.mongodb.net/test" 
Congrats, You are done!

************How to connect your database with your app

Connecting local database:
you can use the below URL for connecting to the local database


mongodb://localhost:27017/natours

syntax:
mongodb://localhost:27017/DatabaseName


Connecting to hosted database:

mongodb+srv://yourusername:<PASSWORD>@cluster0.vsioz83.mongodb.net/DATABASENAME?retryWrites=true&w=majority

For talking to the database there are several drivers we are gonna use Mongoose.

npm install mongoose

********************Using mongoose driver to connect with hosted database

// In config.env file:
NODE_ENV=development
PORT=3000
DATABASE_PASSWORD=yourpassword
DATABASE=mongodb+srv://yourusername:<PASSWORD>@cluster0.vsioz83.mongodb.net/natours?retryWrites=true&w=majority
DATABASE_LOCAL=mongodb://localhost:27017/natours


// In server.js
const DB = process.env.DATABASE.replace(
  '<PASSWORD>',
  process.env.DATABASE_PASSWORD,
);

// here simply getting the url from env file

mongoose
  .connect(DB, {
    useNewUrlParser: true,
    useCreateIndex: true,
    useFindAndModify: false,
  })
  .then((con) => {
    console.log(con.connections);
    console.log('Database Connected Successfully');
  });


// here mongoose.connect returns a promise which have access to connection object which contains the information about our connection


*************What is mongoose

Before getting started lets discuss what is mongoose
Mongoose is ODM (Object data modelling) library for mongoDB and Node.js. It is build on higher level of abstraction. As express is layer on nodeJs similarly mongoose is a layer on MongoDB.  There are several mongoDB driver but we prefer mongoose because of its flexibility and easier development experience. 

Features of mongoose: 
1. Shemas to model data and relationships.
2. Easy Data validation.
3. Simple query API
4. Middlerwares etc.

Mongoose Schema: Where we model our data, by describing the structure of the data, default values and validations.
Mongoose model: its a wrapper for the schema, providing an interface to the database for CRUD operations.



***********Creating simple schema and model

we will creating our schema and model in sevre.js but we wil shift it in the other directory later.

This is how we create schemas in mongoDB using mongoose:


const tourSchema = new mongoose.Schema({
  name: {
    type: String,
    required: [true, 'A tour must have a name'],
    unique: true,
  },
  rating: {
    type: Number,
    default: 4.5,
  },
  price: {
    type: Number,
    required: [true, 'A tour must have a price'],
  },
});



// Here required option is a validator and the array in required: [true, 'A tour must have a name'], here the second argument is the message which is gonna appear in case the user do not enter the name of tour


NOTE: One thing that you must notice here is that in case the use is sending the information which is not in our schemas then in this case we that data will be simply ignored and only that data will be allowed to go into the database which is included in our schemas.
********Now creating a model out of above schema

const Tour = mongoose.model('Tour', tourSchema);

This is how we create model of our schema. Remember the convention as the name of the model starts with captital letter. Model is nothing its simple our collection.

// Here 'Tour' is the name of our collection but in database it will save as 'tours' (plural) instead of 'Tour'. So don't be confused with it.


***********Creating documents and testing the model
One thing you have to remember is that working with mongoDB model is same as working with javascript classes. For example we create instances of the object to create a new object.
same case will go here as we have created our Tour Model This will act as object now to create a new document we will create its instance using "new" as we do in Classes

so 

const testTour = new Tour({
  name: 'The Forest Hiker',
  rating: 4.7,
  price: 497,
})
  .save()
  .then((doc) => {
    console.log('doc: ', doc);
  })
  .catch((err) => {
    console.log('Error', err);
  });


// here testTour is our new instance of Tour model so this means we can apply all methods on it which we can apply on Tour Model. Thats why we can use save() method to save it.
since save() method returns a promise so we are handling that too.

Btw there is another way of creating the document.

Tour.create({
  name: 'The Forest Hiker',
  rating: 4.7,
  price: 497,
}).then(doc=>{
  console.log(doc)
})

The second one is the easy one


*************Introduction to Backend Architecture, MVC types of logic and more


MVC (Model view controller) Architecture.

Model: This layer concerned with the Application data and business logic
Controller: This layer is responsible for handling user http requests, sending responses and much more.
View: This layer is used when we are doing SSR or for presentational logic.

Application logic vs business logic:

Remember its always impossible to completely separate the business and application logic as these logic overlaps to some extend. We try our best to keep the application logic in our controller and business logic in our model 

Application logic:
Its a code which is more concerned with the working of application such as dealing with request-response cycle. And more technical stuff.
Its also works as the bridge between model and view layer.

Business logic:
Its a code which is more concerned with the business things to solve the problem which is set out to solve such as showing and selling tours in our case.
This logic is directly related to our business rules and needs.
For example:
1. creating new tours in database
2. checking if the user is valid
3. validating user input data
4. Ensuring only users who bought a tour can review it.


****************Creating a new document with mongoose in via post request
exports.createTour = async (req, res) => {
  try {
    console.log('Req.body', req.body);
    const newTour = await Tour.create(req.body);
    console.log('New tour', newTour);

    res.status(200).json({
      status: 'success',
      data: {
        tour: newTour,
      },
    });
  } catch (err) {
    res.status(400).json({
      status: 'fail',
      message: 'Invalid data sent!',
    });
  }
};



******************Reading data from database with mongoose

exports.getAllTours = async (req, res) => {
  try {
    const tours = await Tour.find();

    res.status(200).json({
      status: 'success',
      results: tours.length,
      data: {
        tours: tours,
      },
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};

exports.getTour = async (req, res) => {
  try {
    const tour = await Tour.findById(req.params.id);
    // Tour.findOne({_id: req.params.id})
    res.status(200).json({
      status: 'success',
      data: {
        tour: tour,
      },
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};


NOTE: we are entering the id of the user in the url from the postman
GET 127.0.0.1:3000/api/v1/tours/652263f6f27ee20d54b43c82



***************Updating the data with mongoose

exports.updateTour = async (req, res) => {
  try {
    const tour = await Tour.findByIdAndUpdate(req.params.id, req.body, {
      new: true,
      runValidators: true,
    });
    res.status(200).json({
      status: 'success',
      data: {
        tour: tour,
      },
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};


POSTMAN:  PATCH  127.0.0.1:3000/api/v1/tours/652263f6f27ee20d54b43c82


NOTE: const tour = await Tour.findByIdAndUpdate(req.params.id, req.body, {
      new: true,
      runValidators: true,
    });

findByIdAndUpdate() this method take two arguments one id and other is the changes that we want to change, and third is the option object where we can define some options such as
here new: true means this method will return a new object and runValidators: true means after updating the object the validators must be run to check the validation once again.

IMPORTANT: The body we have sent from the postman was{"price":500} Since the HTTP method  was PATCH instead of PUT thats this method only changed the price and returned the new object with new price. Whereas if you have used PUT method here then by sending the body like { "price":500 } then the put method was completely going to replace the existing object with {"price":500} and we will get {"price":500} only



**************Deleting data using mongoose

exports.deleteTour = async (req, res) => {
  try {
    await Tour.findByIdAndRemove(req.params.id);
    res.status(204).json({
      status: 'success',
      data: null,
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};

// here its a standard practice that we do not send back the promise in case of deleting any object


*************Modeling our Tour Data
const tourSchema = new mongoose.Schema({
  name: {
    type: String,
    required: [true, 'A tour must have a name'],
    unique: true,
    trim: true,
  },
  duration: {
    type: Number,
    required: [true, 'A tour must have a duration'],
  },
  maxGroupSize: {
    type: Number,
    required: [true, 'A tour must have a group size'],
  },
  difficulty: {
    type: String,
    required: [true, 'A tour must have a difficulty'],
  },
  ratingsAverage: {
    type: Number,
    default: 4.5,
  },
  ratingsQuantity: {
    type: Number,
    default: 0,
  },
  price: {
    type: Number,
    required: [true, 'A tour must have a price'],
  },
  priceDiscount: Number,
  summary: {
    type: String,
    trim: true, 
    required: [true, 'A tour must have a summary'],
  },
  description: {
    type: String,
    trim: true,
  },
  imageCover: {
    type: String,
    required: [true, 'A tour must have a cover Image'],
  },
  images: [String],
  createdAt: {
    type: Date,
    default: Date.now(),
  },
  startDates: [Date],
});


//Here Trim will remove spaces in the start and end of the string


Our input body while making HTTP POST Request
{
    "name": "The Snow Adventurer",
    "duration": 4,
    "maxGroupSize": 10,
    "difficulty": "difficult",
    "ratingsAverage": 4.5,
    "ratingsQuantity": 13,
    "price": 997,
    "summary": "Exciting adventure in the snow with snowboarding and skiing",
    "description": "Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua, ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum!\nDolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur, exercitation ullamco laboris nisi ut aliquip. Lorem ipsum dolor sit amet, consectetur adipisicing elit!",
    "imageCover": "tour-3-cover.jpg",
    "images": ["tour-3-1.jpg", "tour-3-2.jpg", "tour-3-3.jpg"],
    "startDates": ["2022-01-05,10:00", "2022-02-12,10:00", "2023-01-06,10:00"]
  }




****************Importing data from file to MongoDB database
NOTE: This script is totally independent of the project. This is here to give you an extra knowledge. How you can transfer you data from you .json file to mongoDB database with the help of mongoose.

// In import-dev-data.js

const fs = require('fs');
const mongoose = require('mongoose');
const dotenv = require('dotenv');

const Tour = require('./../../models/tourmodel'); // Importing out model/collection

dotenv.config({ path: './config.env' });

const DB = process.env.DATABASE.replace(
  '<PASSWORD>',
  process.env.DATABASE_PASSWORD,
);
mongoose
  .connect(DB, {
    useNewUrlParser: true,
    useCreateIndex: true,
    useFindAndModify: false,
    useUnifiedTopology: true,
  })
  // eslint-disable-next-line no-console
  .then(() => console.log('Database Connected Successfully'));

// Readung json file
const tours = JSON.parse(
  fs.readFileSync(`${__dirname}/tours-simple.json`, 'utf-8'),
);
/* parse() JSON parsing is the process of converting a JSON object in text format to a Javascript object
 that can be used inside a program*/

// importing data into DB
const importData = async () => {
  try {
    await Tour.create(tours);
    console.log('Data successfully loaded!');
  } catch (err) {
    console.log(err);
  }
  process.exit();
};

// Deleting already present data in database
const deleteData = async () => {
  try {
    await Tour.deleteMany(); //we will pass nothing so it will delete all the data
    console.log('All previous data deleted successfully');
  } catch (err) {
    console.log(err);
  }
  process.exit();
};

if (process.argv[2] === '--import') {
  importData();
} else if (process.argv[2] === '--delete') {
  deleteData();
}
console.log(process.argv);


//**Explanation of the script
In this file we are simply importing our data from the .json file using fs module and converting it into the Javascript obj using JSON.parse. After that  we are connecting our script to our Database. Simply using create and delete function of mongoose to import new data and delete previous data respectively.


Here the new thing we have to noticed that is process.argv. Yes you are guessing right! we had used this in python. This method is used to access the input from the command line
for example:

node filename.js blah_blah

then on consoloing the process.argv we will get

[
  'C:\\Users\\muham\\AppData\\Roaming\\nvm\\v20.4.0\\node.exe',
  'C:\\Doctor\\Work\\Playground\\NodeJS by Jonas\\Natrous_API\\dev-data\\data\\import-dev-data.js',
  'blah_blah'
]

Using this feature we can create some logic


*************Making the API Better filtering
Making the sorting better for getAllTour Route
We are doing it so as user can apply queries to our API

// In tourController.js

exports.getAllTours = async (req, res) => {
  try {
    const queryObj = { ...req.query };
    const excludedFields = ['page', 'sort', 'limit', 'fields'];
    excludedFields.forEach((el) => delete queryObj[el]); // excluding some keywords
    console.log('req.query: ', req.query);
    console.log('queryObj: ', queryObj);
    const query = await Tour.find(queryObj);
    // here we are passing the queryObj
    const tours = await query;




    res.status(200).json({
      status: 'success',
      results: tours.length,
      data: {
        tours: tours,
      },
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};

NOTE: here queryObj is a hard copy not a shallow copy. Means if we do any changes in the queryObj object it will not
effect the req.query Obj This is the most important trick to create a hard copy in JS.
If we directly assign as const queryObj = req.query then as we know objects are references in JS not the actual object.
So in order to create a hard or deep copy we use destruturing instead of directly assigning to it a variable.

Also note that we do not want our user to go to the pages using query string as "127.0.0.1:3000/api/v1/tours?duration=5&difficulty=easy&page=2" so in order to exclude some key words that we do not want our API should have we are excluding it using loop over them.

**********Making API better filtering advance

here in this section we will deal with some more complex queries such as greater than, less than, greater than equal and less than equal.

As we all know in mongoDB we do query to find such greater or less is this way
// db.tours.find({duration: {$gte:5}})

and in url we can do the same in this way:
127.0.0.1:3000/api/v1/tours?duration[gte]=5

In square brackets we write [operators]

so in our JS code we have to write a logic to deal with gte, lte, gt and lt operators to more advance our filtering query.

127.0.0.1:3000/api/v1/tours?duration[gte]=5
whenever the user hit the url the above query strintg the output of req.query object would be:

{duration: {gte:5}}

the only thing which is missing here is the dollar sign. So lets add that

    const queryObj = { ...req.query }; //creating deep copy

    const excludedFields = ['page', 'sort', 'limit', 'fields'];
    excludedFields.forEach((el) => delete queryObj[el]); // deleting the unwanted keywords
    console.log('req.query: ', req.query);
    console.log('queryObj: ', queryObj);

    // here we are doing some advance filtering
    let queryStr = JSON.stringify(queryObj);
    queryStr = queryStr.replace(/\b(gte|gt|lt|lte)\b/g, (match) => `$${match}`); 
    console.log('queryStr: ', JSON.parse(queryStr));

    const query = await Tour.find(JSON.parse(queryStr));
    // here we are passing the queryObj which is a deep copy

    const tours = await query;

// here we are using regular expression to match the words
the logic we are using is simple we are simple replacing the word with the same word but having a dollar $ sign with it.

JSON.stringify and JSON.parse both are work opposite to eachother.


**************Making API better Sorting 

If user hit "127.0.0.1:3000/api/v1/tours?duration[gte]=5&difficulty=easy&sort=price"
this URL will not work as we have excluded the word sort from the url so now lets add it

using this req.query.sort we can get the value of sort which the user has passed in the url

    let query = Tour.find(JSON.parse(queryStr));
    Tour.find() method returns a query object or data which this method has found.

    // Sorting
       if (req.query.sort) {
      const sortBy = req.query.sort.split(',').join(' ');
      query = query.sort(sortBy);
    } else {
      query = query.sort('-createdAt');
      // This is for default sorting when user does not specify any sorting
    }

NOTE: We are not over writting the above queries. We are making a chain or you can say we are passing our URL through different layers so that It can hadle all cases



*******************Making API better limiting field
It is always a good practice to receive as little data as possible from the user so that we can reduce the bandwith. 

127.0.0.1:3000/api/v1/tours?duration[gte]=5&fields=name,price,duration

here the user is specifying only specific fields

we can deal with this query in the similar way as we did in sorting

   if (req.query.fields) {
        const fields = req.query.fields.split(',').join(' ');
        query = query.select(fields);
      } else {
        query = query.select('-__v');
      }

// here  you have noticed that there is a negative sign with __v field. In this case __v is field created by the mongoDB in the Database automatically we do not want our user to see this unnecessary info so using select method -ve means exclude or unselect.

NOTE: In any case you want any specific info which is in your schema and you want to hide it from access you can simply use select:false property in the schema as:

  createdAt: {
    type: Date,
    default: Date.now(),
    select: false,
  }

now the createdAt field will not be displayed


****************Making API Better pagination
The amount of data per page we want to limit
  // Pagination
    const page = req.query.page * 1 || 1; //multiplying by 1 to convert string into a number
    const limit = req.query.limit * 1 || 100;
    const skip = (page - 1) * limit;
    query = query.skip(skip).limit(limit);
    // Below we are checking that a page does exists or not
    if (req.query.page) {
      const numTour = await Tour.countDocuments();
      if (skip >= numTour) throw new Error('This page does not exists');
    }

127.0.0.1:3000/api/v1/tours?duration[gte]=5&page=1&limit=3

********Making API better Aliasing
So let assume that the user wants to get the top 5 cheap tour then the user must have to enter the query like below:
/limit=5&sort=-ratingsAverage,price

so in order to make it simple and more easy to write we will use alias for top 5 cheap tours

// In tourRouter.js
router
  .route('/top-5-cheap')
  .get(tourController.aliasTopTours, tourController.getAllTours);

created a new route which runs a middleware called aliasTopTours

// In tourController.js
// pre-filling the query string
exports.aliasTopTours = (req, res, next) => {
  req.query.limit = '5';
  req.query.sort = '-ratingsAverage,price';
  req.query.fields = 'name,price,ratingsAverage,summary,difficulty';
  next();
};


Here we are prefilling our query so that our link will look like this 

127.0.0.1:3000/api/v1/tours/top-5-cheap

behind the scenes our query will be 

127.0.0.1:3000/api/v1/tours/limit=5&sort=-ratingsAverage,price&fields=name,price,ratingsAverage,summary,difficulty


*************Summary
exports.getAllTours = async (req, res) => {
  try {
     // here queryObj is a hard copy not a shallow copy. Means if we do any changes in the queryObj object it will not
     //effect the req.query Obj This is the most important trick to create a hard copy in JS.
     // If we directly assign as const queryObj = req.query then as we know objects are references in JS not the actual object.
     // So in order to create a hard or deep copy we use destruturing instead of directly assigning to it a variable.

    const queryObj = { ...req.query };
    const excludedFields = ['page', 'sort', 'limit', 'fields'];
     excludedFields.forEach((el) => delete queryObj[el]);
     console.log('req.query: ', req.query);

     // Doing some advance filtering
     let queryStr = JSON.stringify(queryObj);
     // here we are passing the queryObj which is a deep copy
     queryStr = queryStr.replace(/\b(gte|gt|lt|lte)\b/g, (match) => `$${match}`);

     let query = Tour.find(JSON.parse(queryStr));

     Sorting

    if (req.query.sort) {
      const sortBy = req.query.sort.split(',').join(' ');
      query = query.sort(sortBy);
    } else {
      query = query.sort('-createdAt');
      // This is for default sorting when user does not specify any sorting

      if (req.query.fields) {
        const fields = req.query.fields.split(',').join(' ');
        query = query.select(fields);
      } else {
        query = query.select('-__v');
      }
    }
    // Pagination
    const page = req.query.page * 1 || 1; //multiplying by 1 to convert string into a number
    const limit = req.query.limit * 1 || 100;
    const skip = (page - 1) * limit;
    query = query.skip(skip).limit(limit);
    // Below we are checking that a page does exists or not
    if (req.query.page) {
      const numTour = await Tour.countDocuments();
      if (skip >= numTour) throw new Error('This page does not exists');
    }
    const tours = await query;

    res.status(200).json({
      status: 'success',
      results: tours.length,
      data: {
        tours: tours,
      },
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};


********Refractoring the code using classes

Now its time to make this features code in the separate folder so that we could use it in other code as well

make a directory namely "utils" and inside that folder create a file called "apiFeatures.js"

// In apiFeatures.js

class APIFeatures {
  constructor(query, queryString) {
    this.query = query; // query is the data present in Tour model i.e Tour.find()
    this.queryString = queryString; //queryString is a query which coming from express
  }

  filter() {
    // here this.queryString is equal to req.query
    // here queryObj is a hard copy not a shallow copy. Means if we do any changes in the queryObj object it will not
    //effect the req.query Obj This is the most important trick to create a hard copy in JS.
    // If we directly assign as const queryObj = req.query then as we know objects are references in JS not the actual object.
    // So in order to create a hard or deep copy we use destruturing instead of directly assigning to it a variable.

    const queryObj = { ...this.queryString };
    const excludedFields = ['page', 'sort', 'limit', 'fields'];
    excludedFields.forEach((el) => delete queryObj[el]);
    // console.log('req.query: ', req.query);

    // Doing some advance filtering
    let queryStr = JSON.stringify(queryObj);
    // here we are passing the queryObj which is a deep copy
    queryStr = queryStr.replace(/\b(gte|gt|lt|lte)\b/g, (match) => `$${match}`);

    this.query = this.query.find(JSON.parse(queryStr));

    return this;
  }

  sort() {
    if (this.queryString.sort) {
      const sortBy = this.queryString.sort.split(',').join(' ');
      this.query = this.query.sort(sortBy);
    } else {
      this.query = this.query.sort('-createdAt');
      // This is for default sorting when user does not specify any sorting
    }
    return this;
  }

  limitFields() {
    if (this.queryString.fields) {
      const fields = this.queryString.fields.split(',').join(' ');
      this.query = this.query.select(fields);
    } else {
      this.query = this.query.select('-__v');
    }
    return this;
  }

  paginate() {
    const page = this.queryString.page * 1 || 1; //multiplying by 1 to convert string into a number
    const limit = this.queryString.limit * 1 || 100;
    const skip = (page - 1) * limit;
    this.query = this.query.skip(skip).limit(limit);

    return this;
  }
}

module.exports = APIFeatures;


we have replaced req.query with this.queryString and query with this.query
1. here query is the data present in Tour model i.e Tour.find()
2. queryString is a query which coming from express i.e req.query


// In tourController.js

const Tour = require('./../models/tourmodel');

 const features = new APIFeatures(Tour.find(), req.query)
      .filter()
      .sort()
      .limitFields()
      .paginate();
    const tours = await features.query;

// Here we are simply creating a new instance of APIFeature class and applying methods on it which we have created in original APIFeature class.

*************Aggregartion pipeline matching and grouping

The Idea is that all our document will pass through a collection of processes such as calculating avgs etc.
we will make this pipeline.


Aggregation pipeline is basically a mongoDB feature which we will access with the help of Mongoose.

The data will pass through the multiple stages and that will transform the data into an aggregated result.

// In toursController.js
exports.getTourStats = async (req, res) => {
  try {
    const stats = await Tour.aggregate([
      {
        $match: { ratingsAverage: { $gte: 4.5 } },
      },
      {
        $group: {
          _id: { $toUpper: '$difficulty' },
          // _id: '$ratingsAverage',
          numTours: { $sum: 1 },
          numRating: { $sum: '$ratingsQuantity' },
          avgRating: { $avg: '$ratingsAverage' },
          avgPrice: { $avg: '$price' }, // here price is the name of the field
          minPrice: { $min: '$price' },
          maxPrice: { $max: '$price' },
        },
      },
      {
        $sort: {
          avgPrice: 1, // In sort object only those fields name will work which we have specified above in the group stage.
        },
      },
 //     {
 //       $match: { _id: { $ne: 'EASY' } },
 //     },
    ]);

    res.status(200).json({
      status: 'success',
      data: { stats },
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};

// Here each object is stage. In this case we have made three stages:
1. In first stage we are matching or you can say selecting
2. In second stage we are grouping our data in terms of difficulty,
3. we are sorting our data

// In tourRoutes.js

router.route('/tour-stats').get(tourController.getTourStats);


// here we have created a separate route to get all the stats related to our tours.



*********Solving a business problem using Aggregation Pipeline:
The problem is to get the busiest month for natours company

// In tourController.js

exports.getMonthlyPlane = async (req, res) => {
  try {
    const year = req.params.year * 1;


    const plan = await Tour.aggregate([
      {
        $unwind: '$startDates',
      },
      {
        $match: {
          startDates: {
            $gte: new Date(`${year}-01-2021`),
            $lte: new Date(`${year}-12-31`),
          },
        },
      },
      {
        $group: {
          _id: { $month: '$startDates' },
          numTourStarts: { $sum: 1 },
          tours: { $push: '$name' },
        },
      },
      { $addFields: { month: '$_id' } },
      {
        $project: {
          // project is used for hiding a field
          _id: 0,
        },
      },
      {
        $sort: { numTourStarts: -1 }, //-1 for descending
      },
      {
        $limit: 6, //This is just limiting our number of output documents
      },
    ]);
    res.status(200).json({
      status: 'success',
      data: {
        plan,
      },
    });
  } catch (err) {
    res.status(404).json({
      status: 'fail',
      message: err,
    });
  }
};


// This is the aggregation pipe line. Here, "$unwind" Deconstructs an array field from the input documents to output a document for each element. Each output document is the input document with the value of the array field replaced by the element.


// In tourRoutes.js
router.route('/monthly-plan/:year').get(tourController.getMonthlyPlane);

// The input url: 127.0.0.1:3000/api/v1/tours/monthly-plan/2021

ouput: 
{
    "status": "success",
    "data": {
        "plan": [
            {
                "numTourStarts": 3,
                "tours": [
                    "The Forest Hiker",
                    "The Sea Explorer",
                    "The Sports Lover"
                ],
                "month": 7
            },
            {
                "numTourStarts": 2,
                "tours": [
                    "The Sea Explorer",
                    "The Park Camper"
                ],
                "month": 8
            },
            {
                "numTourStarts": 2,
                "tours": [
                    "The Forest Hiker",
                    "The Star Gazer"
                ],
                "month": 10
            },
            {
                "numTourStarts": 2,
                "tours": [
                    "The Sea Explorer",
                    "The City Wanderer"
                ],
                "month": 6
            },
            {
                "numTourStarts": 2,
                "tours": [
                    "The Forest Hiker",
                    "The Wine Taster"
                ],
                "month": 4
            },
            {
                "numTourStarts": 2,
                "tours": [
                    "The City Wanderer",
                    "The Star Gazer"
                ],
                "month": 3
            }
        ]
    }
}


**************Virtual properties

// In tourModel.js

const tourSchema = new mongoose.Schema(
  {
   .....Our Schemas
  },
  {
    toJSON: { virtuals: true },
    toObject: { virtuals: false },
  },
);
// Here above in schema options we have set to show our created virtuals to true in case of JSON and to hide them in case of object.

tourSchema.virtual('durationWeek').get(function () {
  return this.duration / 7;
});

// here the virtual is a category which we specify when we do not want to store the information in the database but just want to
// show. As it doesn't make sense to store the same info with different units. Now from schema options we can manage this virtual property. REMEMBER: we cannot use queries on virtuals as they are actually not a part of database.

*************Document Middlerware

In monsgoose we can create middleware which can run before and after an event. In mongoose they are often called pre or post Hooks.

There are four types of middleware in mongoose
1. Document
2. Query
3. Aggregate
4. Model

**Document Middleware
Just like the virtual property we will define our document middle ware on our schema in model.js file

// In model.js

// DOCUMENT MIDDLEWARE: runs before .save() and .create()
// This middleware will not work for .insertMany()
tourSchema.pre('save', function (next) {
  this.slug = slugify(this.name, { lower: true });
  next();
});

tourSchema.pre('save', function (next) {
  console.log('will save document');
  next();
});

// DOCUMENT MIDDLEWARE: runs after the .save() and .create()
tourSchema.post('save', function (doc, next) {
  console.log('doc: ', doc);
  next();
});

here this keyword is pointing towards the current document that is going to be saved
NOTE: Dont forget to add slug : String in schemas


**Query Middleware

// IN model.js

//QUERY MIDDLEWARE

// tourSchema.pre('find', function (next) {
//   this.find({ secretTour: { $ne: true } });
//   next();
// });
// This query will not work for findOne, findOneAndUpdate etc.
//To make it work for that we are using regular expressions
tourSchema.pre(/^find/, function (next) {
  this.find({ secretTour: { $ne: true } });

  this.start = Date.now();
  next();
});
// here this experssion /^find/ means that any query starting with find

tourSchema.post(/^find/, function (docs, next) {
  console.log(docs);
  console.log(`The Query Took ${(Date.now() - this.start) / 1000} seconds`);

  next();
});


NOTE: You may have noticed that all middlewares look same but the difference between the query and document middleware is that document works with save and query works with find etc.

post hook in mongoose also have access to document object.

in case of pre hook query middleware the this keyword is pointing towared the current query object on which we can apply all methods

Dont forget to add the below in you schemas:
  secretTour: {
      type: Boolean,
      default: false,
    }, 



**AGGREATE Middleware

//AGGREGATION MIDDLEWARE
tourSchema.pre('aggregate', function (next) {
  this.pipeline().unshift({ $match: { secretTour: { $ne: true } } });
  console.log('aggregation middleware pipeline: ', this.pipeline());

  next();
});

Here unshift is a javascript method which is used to add the elements at the beginning of the array similarly we have shift method which is used to add elements at the end of the array



**********Data Validation in mongoose
Validation simply means that whether the entered data is in right format or not.
There is another concept called sanitization. Which simply means whether the entered data is clean or not.
It is a GOLDEN standard in backend development that never ever receive data from backend as it is.

We have added some built in validators in our Model schemas which are given below:
const tourSchema = new mongoose.Schema(
  {
    name: {
      type: String,
      required: [true, 'A tour must have a name'],
      unique: true,
      trim: true,
      maxlength: [40, 'A tour must have less than or equal to 40 characters'],
      minlength: [
        10,
        'A tour name must have greater or equal than 10 character',
      ],
    },
    slug: String,
    duration: {
      type: Number,
      required: [true, 'A tour must have a duration'],
    },
    maxGroupSize: {
      type: Number,
      required: [true, 'A tour must have a group size'],
    },
    difficulty: {
      type: String,
      required: [true, 'A tour must have a difficulty'],
      enum: {
        values: ['easy', 'medium', 'difficult'],
        message: 'Difficulty can either be: easy, medium or difficult',
      },
      
    },
    ratingsAverage: {
      type: Number,
      default: 4.5,
      minlength: [1, 'Rating must be above 1.0'],
      maxlength: [5, 'Rating must be below 5.0'],
    },
    ratingsQuantity: {
      type: Number,
      default: 0,
    },
    price: {
      type: Number,
      required: [true, 'A tour must have a price'],
    },
    priceDiscount: Number,
    summary: {
      type: String,
      trim: true, //Trim will remove spaces in the start and end of the string
      required: [true, 'A tour must have a summary'],
    },
    description: {
      type: String,
      trim: true,
    },
    imageCover: {
      type: String,
      required: [true, 'A tour must have a cover Image'],
    },
    images: [String],
    createdAt: {
      type: Date,
      default: Date.now(),
      select: false,
    },
    startDates: [Date],
    secretTour: {
      type: Boolean,
      default: false,
    },
  },
  {
    toJSON: { virtuals: true },
    toObject: { virtuals: false },
  },
);

//here enum is only for strings which are allowed

*************Custom validators
Sometimes builtin validators are not enough to meet our requirements. Custom validators are here to fill the gap.
Custom validators are nothing just a simple function which returns either true or false. On the basis of which the input is accepted

 price: {
      type: Number,
      required: [true, 'A tour must have a price'],
    },
    priceDiscount: {
      type: Number,
      validate: {
        validator: function (val) {
          // here this keyword is pointing toward the value entered by the user on creating NEW document
          return val < this.price;
        },
        message: 'Discount price ({VALUE}) must be less than the actual price',
      },
    },

// This is how we define a custom validator.

//There are several libraries for making custom validators we are gonna use "validator"

npm install validator

  name: {
      type: String,
      required: [true, 'A tour must have a name'],
      unique: true,
      trim: true,
      maxlength: [40, 'A tour must have less than or equal to 40 characters'],
      minlength: [
        10,
        'A tour name must have greater or equal than 10 character',
      ],
      validate: [validator.isAlpha, 'Tour Name must only contain characters'],
    },

here .isAlpha is a method which allows characters only in the name not even numbers as numbers are not count in character. Not even spaces are not allowed.


************Error handling in nodeJS
We are going to use NDB (node debugger) for error handling
now go to your package.json file and add 

"debug": "ndb server.js" 
in your script tag

now npm run debug

chromium debugger window will be open

This tool is same as chrome debugger but it provides more feature and control. Like chrome debugger you can add break points in it and so on.



***************Handling unhandled route error
// In app.js

app.all('*', (req, res, next) => {
  res.status(404).json({
    status: 'fail',
    message: `Can't find ${req.originalUrl} on this server!`,
  });
});

this is a middleware function for all urls and for all http methods

**IMP**: Don't place middleware in the wrong place as we all know middleware run in the order as they are specified.
So we have defined this middlware in the last of the app.js so that in case of request failure this middleware should reach otherwise it should not.


************Error Handling Overview
There are two types of error
1. Operational Errors (Error which we can predict that may occure at some point somewhere in future e.g invalid path access by the user, failed to connect to the server/database.)
2. Programming Errors (Errors or bugs in our code introduced by the programmer or developer while writing code e.g reading properties from undefined variable)

So to solution to these error we have to create a "Global Error handling middleware" which will deal with error coming from all our application.


**************Implementing Global Error Handling middleware************

// Creating error
app.all('*', (req, res, next) => {
  const err = new Error(`Can't find ${req.originalUrl} on this server!`);
  err.status = 'fail';
  err.statusCode = 404;
  next(err);
});


// Global Error handling middleware
app.use((err, req, res, next) => {
  err.statusCode = err.statusCode || 500;
  err.status = err.status || 'error';
  res.status(err.statusCode).json({
    status: err.status,
    message: err.message,
  });
});

//NOTE: whenever there is middleware with first argument err then Express will automatically assume it as global error handling middleware. And whenever we pass anything inside next(err) function it will be considered that we have passed an error inside next function.

Now we all just need to create error as we have created above then this global middleware will be called automatically.

****************Creating Error Class and refracting the code

//create file in utils called appError.js

// In appError.js
class AppError extends Error {
  constructor(message, statusCode) {
    super(message);

    this.statusCode = statusCode;
    this.status = `${statusCode}`.startsWith('4') ? 'fail' : 'error';
    this.isOperational = true;

    Error.captureStackTrace(this, this.construtor);
  }
}

module.exports = AppError;

// here isOperational = true; would be helpful later on in distinguish between the operational and programming errors

//here we have used the concept of inheritance as AppError inherit inside Error class. In case inheritance we always call super function to call the parent class constructor function. We are calling super function by message property as built Error class only accepts message property.
// stack trace tells you the location of the error as console.log(err.stack)
but in our case we want that whenever a new class is created it should not be traced.	
// we have not done this.message = message as we know super(message) will automatically set the incoming message to message property


//create a new file in controller folder called errorController.js
// In errorController.js

module.exports = (err, req, res, next) => {
  err.statusCode = err.statusCode || 500;
  err.status = err.status || 'error';
  res.status(err.statusCode).json({
    status: err.status,
    message: err.message,
  });
};


//In app.js
const AppError = require('./utils/appError');
const globalErrorHandler = require('./controllers/errorController');

app.all('*', (req, res, next) => {
  next(new AppError(`Can't find ${req.originalUrl} on this server!`, 404));
});

app.use(globalErrorHandler); // this middleware is getting called due to the next function in above middleware.
// This is how we can pass arguments to our Error handling class


**************Catching errors in async Functions
// Create new file in utils folder called catchAsync.js

// In catchAsync.js

module.exports = (fn) => {
  return (req, res, next) => {
    fn(req, res, next).catch((err) => next(err));
  };
};

// we have done this just for the sake to clean our code as there was repeatablity of calling catch block. In order to avoid this we have created a function which receives an other function that function would be our async function.
We are returing a function in this function so that express call it. This is basically a async code work thing.

JS allows to apply catch methods on functions.

now we just have to wrap our async functions in tourController inside this catchAsync function we also have to add next argument property in our async function so that each async function comes with its own next function. Here next(err) will call the global error handling middleware.

// In tourController.js
const catchAsnyc = require('./../utils/catchAsync');
const AppError = require('../utils/appError');

exports.getAllTours = catchAsnyc(async (req, res, next) => {
  // EXECUTE QUERY
  const features = new APIFeatures(Tour.find(), req.query)
    .filter()
    .sort()
    .limitFields()
    .paginate();
  const tours = await features.query;

  res.status(200).json({
    status: 'success',
    results: tours.length,
    data: {
      tours: tours,
    },
  });
});

exports.getTour = catchAsnyc(async (req, res, next) => {
  const tour = await Tour.findById(req.params.id);
  // Tour.findOne({_id: req.params.id})
  if (!tour) {
    return next(new AppError('No Tour Found with this ID', 404));
  }
  res.status(200).json({
    status: 'success',
    data: {
      tour: tour,
    },
  });
});

exports.createTour = catchAsnyc(async (req, res, next) => {
  const newTour = await Tour.create(req.body);
  res.status(200).json({
    status: 'success',
    data: {
      tour: newTour,
    },
  });
});

exports.updateTour = catchAsnyc(async (req, res, next) => {
  const tour = await Tour.findByIdAndUpdate(req.params.id, req.body, {
    new: true,
    runValidators: true,
  });
  if (!tour) {
    return next(new AppError('No Tour Found with this ID', 404));
  }
  res.status(200).json({
    status: 'success',
    data: {
      tour: tour,
    },
  });
});

exports.deleteTour = catchAsnyc(async (req, res, next) => {
  const tour = await Tour.findByIdAndRemove(req.params.id);
  if (!tour) {
    return next(new AppError('No Tour Found with this ID', 404));
  }
  res.status(204).json({
    status: 'success',
    data: null,
  });
});

exports.getTourStats = catchAsnyc(async (req, res, next) => {
  const stats = await Tour.aggregate([
    {
      $match: { ratingsAverage: { $gte: 4.5 } },
    },
    {
      $group: {
        _id: { $toUpper: '$difficulty' },
        // _id: '$ratingsAverage',
        numTours: { $sum: 1 },
        numRating: { $sum: '$ratingsQuantity' },
        avgRating: { $avg: '$ratingsAverage' },
        avgPrice: { $avg: '$price' },
        minPrice: { $min: '$price' },
        maxPrice: { $max: '$price' },
      },
    },
    {
      $sort: {
        avgPrice: 1,
      },
    },
    {
      $match: { _id: { $ne: 'EASY' } },
    },
  ]);

  res.status(200).json({
    status: 'success',
    data: { stats },
  });
});

exports.getMonthlyPlane = catchAsnyc(async (req, res, next) => {
  const year = req.params.year * 1;
  //Deconstructs an array field from the input documents to output a document for each element.
  //Each output document is the input document with the value of the array field replaced by the element.

  const plan = await Tour.aggregate([
    {
      $unwind: '$startDates',
    },
    {
      $match: {
        startDates: {
          $gte: new Date(`${year}-01-2021`),
          $lte: new Date(`${year}-12-31`),
        },
      },
    },
    {
      $group: {
        _id: { $month: '$startDates' },
        numTourStarts: { $sum: 1 },
        tours: { $push: '$name' },
      },
    },
    { $addFields: { month: '$_id' } },
    {
      $project: {
        // project is used for hiding a field
        _id: 0,
      },
    },
    {
      $sort: { numTourStarts: -1 }, //-1 for descending
    },
    {
      $limit: 6, //This is just limiting our number of output documents
    },
  ]);
  res.status(200).json({
    status: 'success',
    data: {
      plan,
    },
  });
});

// NOTE:  See how next(new AppError('No Tour Found with this ID', 404)); 
making our code simple here AppError is just a helper class which make our error more readable and then pass to the next which pass it to our global error handler
	


****************Distinguishing operational and programming errors

// In errorController.js
const sendErrorDev = (err, res) => {
  res.status(err.statusCode).json({
    status: err.status,
    error: err,
    message: err.message,
    stack: err.stack,
  });
};
const sendErrorProd = (err, res) => {
  // operational error that are trusted error: send message to the client
  if (err.isOperational) {
    res.status(err.statusCode).json({
      status: err.status,
      message: err.message,
    });
  
  
  // Programming error or other unknown errors: don't want to leak the details to the client
  } else {
    // 1) log error
    console.error('ERROR 💣', err)

    // send generic error
    res.status(500).json({
      status: 'error',
      message: 'Something went wrong!',
    });
  }
};
module.exports = (err, req, res, next) => {
  err.statusCode = err.statusCode || 500;
  err.status = err.status || 'error';

  if (process.env.NODE_ENV === 'development') {
    sendErrorDev(err, res);
  } else if (process.env.NODE_ENV === 'production') {
    sendErrorProd(err, res);
  }
};


****************Handling errors for Invalid IDs, duplicate field names, mongoose validation error

// In errorcontroller.js
const AppError = require('./../utils/appError');
const handleCastErrorDB = (err) => {
  const message = `Invalid ${err.path}: ${err.value}`;
  return AppError(message, 400);
};
const handleDuplicateFieldsDB = (err) => {
  const value = err.errmsg.match(/(["'])(?:(?=(\\?))\2.)*?\1/)[0];
  console.log(value);
  const message = `Duplicate field value: ${value}. Please use another value`;
  return AppError(message, 400);
};
const handleValidationErrorsDB = (err) => {
  const errors = Object.values(err.errors).map((el) => el.message);
  const message = `Invalid input data ${errors.join('. ')}`;
  return new AppError(message, 400);
};

// REST of the code..

module.exports = (err, req, res, next) => {
  err.statusCode = err.statusCode || 500;
  err.status = err.status || 'error';

  if (process.env.NODE_ENV === 'development') {
    sendErrorDev(err, res);
  } else if (process.env.NODE_ENV === 'production') {
    let error = { ...err }; //trick or creating hard copy
    if (error.name === 'CastError') (error) => handleCastErrorDB(error);
    if (error.code === 11000) (error) => handleDuplicateFieldsDB(error);
    if (error.name === 'ValidationError')
      (error) => handleValidationErrorsDB(error);
    sendErrorProd(error, res);
  }
};


we have made changes for production mode

***********Unhandled promise rejection


There might be a chance that a promise get rejected somewhere in our application but In order to have safety net to prevent that error we use Event listeners

const server = app.listen(port, () => {
  // eslint-disable-next-line no-console
  console.log(`Server is running on port ${port}`);
});

process.on('unhandledRejection', (err) => {
  console.log(err.name, err.message);
  console.log('UNHANDLED REJECTION! Shutting down...');
  server.close(() => {
    process.exit(1);
  });
});


*****************Uncaught Exception
In uncaught exception the termination of application is necessary as in uncaught exception the application is not in the clean state so in such  state application must be terminate but in case of uncaught rejection the termination of applicaion is not necessary

console.log(x)

where x is undefined willl give an uncaught exception.

It should be on the top- of our node js application
even before the app

// In server.js
process.on('uncaughtException', (err) => {
  console.log('UNCAUGHT EXCEPTION');
  process.exit(1);
});



NOTE: Error handling is one of the most complex topic in node js


***********Authentication, Autherization and security

Creating user model and schema

// In models create a file called userModel.js

//In userModel.js

const mongoose = require('mongoose');
const validator = require('validator');

const userSchema = new mongoose.Schema({
  name: {
    type: String,
    require: [true, 'Please tell use your name'],
  },
  email: {
    type: String,
    require: [true, 'Please provide your email'],
    unique: true,
    lowercase: true,
    validate: [validator.isEmail, 'Please provide a valid email'], //isEmail is a builtin function validator npm doucment.
  },
  photo: { type: String, require: true },
  password: {
    type: String,
    require: [true, 'Please provide a password'],
    minlength: 8,
  },
  passwordConfirm: {
    type: String,
    require: [true, 'Please confirm your password'],
  },
});

const User = mongoose.model('User', userSchema); //it will store as users in mongoDB automatically

module.exports = User;


************Creating new Users
Create a file in controller folder called authController.js

//In authController.js

const User = require('./../models/userModel');
const catchAsnyc = require('./../utils/catchAsync');

exports.signup = catchAsnyc(async (req, res) => {
  const newUser = await User.create(req.body);

  res.status(201).json({
    status: 'success',
    data: {
      user: newUser,
    },
  });
});


// Now go to the Routes folder and go to userRouter.js and add a new route
// In userRouter.js


//...Rest of the code

router.post('/signup', authController.signup);

//...Rest of the code

***Testing signup endpoint

go to the postman and check for

127.0.0.1:3000/api/v1/users/signup

// send this below raw json body to this end point with POST method
{
    "name":"test",
    "email":"test@gmail.com",
    "password":"test1234",
    "passwordConfirm":"test1234"
}

**********Managing passwords

We should not store our passowords as plain text in the database as hacker can access them which may cause some damage. So in order to encrypt our passwords we will implement this functionality in our Model not in the controller.
Always follow "Fat model Thin controller"

Go to the userModel.js

First validate the password that the entered password and confirm password both are same. Remember that validation is nothing to work with out DB. We are doing it only for the user to not have any mistake while choosing his password. This means that we are not going save the confirm password field in our database on the actual password field will be stored.

passwordConfirm: {
    type: String,
    require: [true, 'Please confirm your password'],
    validate: {
      //This will work only on saving or creating a user
      validator: function (el) {
        return el === this.password;
      },
      message: 'Passwords are not the same',
    },
  },

// for validation you just have t0 add the above function in your schema

now before storing the password first salt it and then hash it and then store it into the database. here salting before hashing will always create a hased version which won't be the same for same string. This is the power of salting
We are doing this using middleware.

userSchema.pre('save', async function (next) {
  //Only run this function when the password is actually modified
  if (!this.isModified('password')) return next();

  //Hashing the password

  this.password = await bcrypt.hash(this.password, 12);

  //Deleting the confirm password unnecessaary field
  this.passwordConfirm = undefined;
  next();
});

//this middleware will work before the data is going to store in the database.


****************HOW JWT authentcation works
JWT is perfect for RESTful APIs as it matches the principle of stateless.
**General Overview**

Let say, a client made an http post request to login into his account with his email and password. The server first validate the user. If the user is validated then generate a JWT token and sends back to the client. Now this JWT Token is like a passport. Now this token is store in cookies or local storage. Server does not know this JWT token as it is stateless. 
Now onward whenever the user the try to access any protected route the user will send show his JWT token and server will verify it and then will allow access to the user to that proctected route.


JWT:

JWT consists of three parts:
1. Header:

header is simply a meta data or info about the token e.g
{
	"alg": "HS256",
	"type": "JWT"
}


2. Payload
payload is actually the data we want we can decode this data. Remember that this data is not encrypted it is just encoded. e.g
{
	"_id": "5dsfdsc5ds1cscds6sdfdsfsdds4ds5gfham"
}



3. Signature
Signature is made up of three things
header
payload
and a secret key which is stored in our server

e.g

{
	HMACSHA256(base64UrlEncoded(header) + "." + base64UrlEncoded(payload), my-secret-key)
}



JWT = Header + payload + signature
where signature = (header + payload + secret key)

****Deep dive in behind the scenes of how JWT works

when the JWT is received by the client it acts as a passport.

when the user try to access any protected route he shows his JWT token. The verification takes the header and payload and create a Test signature using the secret which is stored in the server. Then the verifier compares only the "Original Signature" with the "Test Signature" if they get matched the user will be allow to access otherwise he won't. Moreover, this verification will also make sure that header and payload are not changed as we all know signature is made up of header, payload and a secret key. 



************Implementing the authenitcation, Signing in the new user:

NOTE: Authentication is the most important part of an application. It should be done very very carefully. For authentication there are several libraries but they do not provide you the full control so therefore we are not going to use any library we will instead write the whole code by ourselves and we will only use one library called "jsonwebtoken" to deal with all JWT stuff.


while generating the secret key most of the developers do mistake they simply make a simple string which is wrong. The secret key must be a 32 character long string which should be complex and not easy to guess.

So I usually prefer to run the below command to generate a random key in the terminal

> require('crypto').randomBytes(32).toString('base64').slice(0,32)

Syntax: require('crypto').randomBytes(size).toString('base64').slice(0,size)

incase above dont work: node -e "console.log(require('crypto').randomBytes(32).toString('base64').slice(0,32))"


**************Signing up the user and sending JWT back to the client
//In authController.js
const jwt = require('jsonwebtoken');
const User = require('./../models/userModel');
const catchAsnyc = require('./../utils/catchAsync');

exports.signup = catchAsnyc(async (req, res) => {
// here we are receiving only specific data from the client to prevent the unnecessary or harmful data
  const newUser = await User.create({
    name: req.body.name,
    email: req.body.email,
    password: req.body.password,
    passwordConfirm: req.body.passwordConfirm,
  });

//generating jwt
  const token = jwt.sign({ id: newUser._id }, process.env.JWT_SECRET, {
    expiresIn: process.env.JWT_EXPIRES_IN,
  });

//sending back response to the client
  res.status(201).json({
    status: 'success',
    token: token,
    data: {
      user: newUser,
    },
  });
});

// Here we are simply singing up/ creating a new user so there is no any need here to verify the user. In the next step we are going to implement this.


************Logging the user In
// creating a login route in userRoute.js

//In userRoutes.js

router.post('/login', authController.login);


//In authController.js
const jwt = require('jsonwebtoken');
const User = require('./../models/userModel');
const catchAsnyc = require('./../utils/catchAsync');
const AppError = require('./../utils/appError');

const signToken = (id) => {
  return jwt.sign({ id: id }, process.env.JWT_SECRET, {
    expiresIn: process.env.JWT_EXPIRES_IN,
  });
};

exports.login = catchAsnyc(async (req, res, next) => {
  const { email, password } = req.body;

  //checking email and password exists or not

  if (!email || !password) {
    return next(new AppError('Please provide email and password!', 400));
  }

  // Checking the user exist and password is correct.
  const user = await User.findOne({ email: email }).select('+password'); //here + sign is for the fields which are by default not selected in User Model as select:false

  //here correctPassword is our custom made global instance method for user document thats why we can use it here.
  if (!user || !(await user.correctPassword(password, user.password))) {
    return next(new AppError('incorrect email or password', 401));
  }

  // If everything ok, then send token to client
  const token = signToken(user._id);
  res.status(200).json({
    status: 'success',
    token: token,
  });
});

// here correct password is a custom method which we have created it is called global instance method which we have created in userModel.js we could create this method any where but we are following fat model and thin controller principle so thats why...

// so in UserModel.js

userSchema.methods.correctPassword = async function (candidatePassword, userPassword) {
  return await bcrypt.compare(candidatePassword, userPassword);
};

also we do not want our password visible when we do getAllUser request so to prevent it we are adding the following property in our model schema
 password: {
    type: String,
    require: [true, 'Please provide a password'],
    minlength: 8,
    select: false,
  },

//Here till this point a user logged in get authorized and get a jwtToken now our next step would be to protect our routes

***************Protecting the routes Part 1
here we want to protect the getAllUser route which we can protect by using middleware

//In authController.js
exports.protect = catchAsnyc(async (req, res, next) => {
  //Getting the token and check its true or not
  let token;
  if (
    req.headers.authorization &&
    req.headers.authorization.startsWith('Bearer')
  ) {
    token = req.headers.authorization.split(' ')[1];
  }
  console.log('My Token: ', token);

  if (!token) {
    return next(
      new AppError(
        'You are not logged in! Please log in first to get access',
        401,
      ),
    );
  }
  next();

  //verification of token
  //check if user is still exists
  //check if user changed password after the token was issued
});

//In tourRoutes.js
const authController = require('../controllers/authController');

//Rest of the code.....

  .route('/')
  .get(authController.protect, tourController.getAllTours)
  .post(tourController.createTour);



**********Now complete authenticaion 

// In authController.js
exports.login = catchAsnyc(async (req, res, next) => {
  const { email, password } = req.body;

  //checking email and password exists or not

  if (!email || !password) {
    return next(new AppError('Please provide email and password!', 400));
  }

  // Checking the user exist and password is correct.
  const user = await User.findOne({ email: email }).select('+password'); //here + sign is for the fields which are by default not selected in User Model as select:false

  //here correctPassword is our custom made global instance method for user document thats why we can use it here.
  if (!user || !(await user.correctPassword(password, user.password))) {
    return next(new AppError('incorrect email or password', 401));
  }

  // If everything ok, then send token to client
  const token = signToken(user._id);
  res.status(200).json({
    status: 'success',
    token: token,
  });
});

exports.protect = catchAsnyc(async (req, res, next) => {
  //Getting the token and check its true or not
  let token;
  if (
    req.headers.authorization &&
    req.headers.authorization.startsWith('Bearer')
  ) {
    token = req.headers.authorization.split(' ')[1];
  }
  console.log('My Token: ', token);

  if (!token) {
    return next(
      new AppError(
        'You are not logged in! Please log in first to get access',
        401,
      ),
    );
  }

  //verification of token
  const decoded = await promisify(jwt.verify)(token, process.env.JWT_SECRET);

  //check if user is still exists
  const freshUser = await User.findById(decoded.id);
  if (!freshUser) {
    return next(
      new AppError(
        'The token belonging to this user no longer exist. Please login again!',
        401,
      ),
    );
  }

  //check if user changed password after the token was issued
  if (freshUser.changedPasswordAfter(decoded.iat)) {
    return next(
      new AppError('User recently changed password. Please log in again', 401),
    );
  }

  //Grant access to protected route
  req.user = freshUser; //assigning current user to req.user to have access to the current user. This is very very important step
  next();
});

**NOTE**:   req.user = freshUser; //assigning current user to req.user to have access to the current user. This is very very important step


// In userModel.js

userSchema.methods.changedPasswordAfter = function (JWTTimestamp) {
  if (this.passwordChangedAt) {
    const changedTimeStamp = parseInt(
      this.passwordChangedAt.getTime() / 1000,
      10,
    );
    return JWTTimestamp < changedTimeStamp;
  }

  //false means password not changed
  return false;
};


//most of the developer only do authentication algorithm till verification of token. They do not do complete authentication till check if user changed password after the token was issued this is supposed to be done as if someone stole the JWT token of a user and the user to protect himself change his password then the token should also be expired a new token should be generate right? so in this we have done that too. Moreover we have also checked if user is still exists. This is done so that in a case when someone deleted the user from the database and then its token will be there and due to which someone can grant access to the protected routes which should be done. We have deal with this case too.


While access the protecting routes the user must send valid JWT token via headers so in postman go to headers and give key, value as
authorization: Bearer ashfgsadhfdsajasjkd8236482e27e632876217g


*************Advance Postman Setup
First we will setup our environment
we have set two environments namely Dev: Natours and Prod: Natours
we have set URL: http://127.0.0.1 for Dev env
we have set URL: natours.io for Prod env


Now we all know that on login or on creating a new user that is signing up we get a JWT Token and then we send this token from front end inside the headers to get access to the protected routes.
so here we were doing copy and paste the token to test our end points so save out time we will automate this process

so to do that go to your signup and login end points tab in Postman and look for test tab and write a code to programmatically automate the process.
In sigup test script

pm.environment.set("jwt", pm.response.json().token);

In login test script
pm.environment.set("jwt", pm.response.json().token);

//here we are assigning our coming token to jwt variable which would be available through out the environment in postman

now go to your getAllTours tab
look for authorization tab and select Bearer Token and set token to {{jwt}}

************Implenmenting Authorization and role based permissions
Authenticaiton and Authorization both are different things.
Authentication verifies the identity of a user whereas authorization determines the right of access on the basis of the role of the user.

All logged in users are not allowed to perform all the actions in the API only certain users such as admin etc will be allowed to have full control.

So we are first gonna restrict out DeleteTour route, only admin and lead-guide would be allowed to do this.

so to do that first create wrapper function which returns a middleware function 

//In authCOntroller.js
exports.restrictTo = (...roles) => {
  return (req, res, next) => {
    // where roles = ['admin', 'lead-guie'] are allowed
    console.log('roles: ', roles);
    if (!roles.includes(req.user.role)) {
      return next(
        new AppError('You are not have permission to perform this action', 403),
      );
    }
    next();
  };
};
// here we cannot pass aurguments to a middleware function thats why we are wrapping our middleware function
// into a restrictTo wrapper function
// here req.user is the current user as we have stored our current user in req.user in protect route middleware function

//In tourRoutes.js

//Rest of the code....
router
  .route('/:id')
  .get(tourController.getTour)
  .patch(tourController.updateTour)
  .delete(
    authController.protect,
    authController.restrictTo('admin', 'lead-guide'),
    tourController.deleteTour,
  );


here in delete tour route we have introduced two middleware first middlware is protecting the route from unauthenticated user and second one is authorizing the user
NOTE that we are passing two arguments in restrictTo wrapper function which returns a middleware function


****************Reset Password functionality or Fogot password
So here in this functionality there are two methods to implement this 
step 1: The user will send a post request to forgot password route where he will provide an email address. 
Then a reset token will be generated which will not a JSON token but a simple token. That token will be send to the provided email address.
Step 2: User will send back or make a post request to the reset password route with that reset token along with his new or updated password.

*****Step1

Here one thing the you should always remember that the reset token should be encrypted first and then save into the database. Whereas the non encrypted version of the token should be send to cliend via email.
When ever there is a need of function which will must interact with the database or our shema model we always refer to have global instance method functions in our Model.js

// In userModel.js

passwordResetToken: String,
passwordResetExpires: Date,

//add these above two fields in your model schema

userSchema.methods.createPasswordResetToken = function () {
  // generating a token
  const resetToken = crypto.randomBytes(32).toString('hex');

  // encypting the generated token and storing into our database

  this.passwordResetToken = crypto
    .createHash('sha256')
    .update(resetToken)
    .digest('hex');

  console.log({ resetToken }, this.passwordResetToken);
  this.passwordResetExpires = Date.now() + 10 * 60 * 1000;

  return resetToken;
};

// this global instance method will return an unencrypted reset Token and will save an encypted reset token to the database so that later we could compare them. Moreover since this is a global instance method so this would be available through out the document. This key word here will point toward the current document that why to access any field we do this.passwordResetToken

// In userRoutes.js
// Don't forget to create routes for forgot and reset password

router.post('/forgotPassword', authController.forgotPassword);
router.patch('/resetPassword/:token', authController.resetPassword);

// In authConroller.js
exports.forgotPassword = catchAsnyc(async (req, res, next) => {
  // Get the user email tand verify the email
  const user = await User.findOne({ email: req.body.email });
  if (!user) {
    return next(new AppError('There is no user with this email address!', 404));
  }
  // Generate a random token
  const resetToken = user.createPasswordResetToken();
  await user.save({ validateBeforeSave: false });

  // Send that token to the provided email
});

NOTE: here the reason behind using this property { validateBeforeSave: false } is that we are saving encrypted version of resetPassword Token without any validation we are assuming it to correct as we are generating it by ourselve. So here we will get warnings and error so we are just turning off validation for this token saving in database.

**************Sending email/ Forgot Password
To send email via node js we are using nodemailer and for development instead of using our actual emails we are using mailtrap to deal with emails. This mail trap will give us a fake email and password to which we can send emails etc.

// In authController.js

exports.forgotPassword = catchAsnyc(async (req, res, next) => {
  // Get the user email tand verify the email
  const user = await User.findOne({ email: req.body.email });
  if (!user) {
    return next(new AppError('There is no user with this email address!', 404));
  }
  // Generate a random token
  const resetToken = user.createPasswordResetToken();
  await user.save({ validateBeforeSave: false });

  // Send that token to the provided email
  const resetURL = `${req.protocol}://${req.get(
    'host',
  )}/api/v1/users/resetPassword/${resetToken}`;

  const message = `Forgot your password? Submit a PATCH request with your new password and confirm password to: ${resetURL}.\nIf you didn't forget your password then Please ignore this email.`;
  try {
    await sendEmail({
      email: user.email,
      subject: 'You Password Reset Token (Valid for 10 mins)',
      message: message,
    });

    res.status(200).json({
      status: 'success',
      message: 'Token sent to email!',
    });
  } catch (err) {
    (user.passwordResetToken = undefined),
      (user.passwordResetExpires = undefined),
      await user.save({ validateBeforeSave: false });
    return next(
      new AppError(
        'There was an error in sending the email. Try again later!',
        500,
      ),
    );
  }
});

// Here we have completed our three step forgot password mechanism. In catch block in case of any error we have set our generated reset tokens to undefined.

// In utils folder email.js
const nodemailer = require('nodemailer');

const sendEmail = async (options) => {
  // 1) Create a transporter
  const transporter = nodemailer.createTransport({
    host: process.env.EMAIL_HOST,
    port: process.env.EMAIL_PORT,
    auth: {
      user: process.env.EMAIL_USERNAME,
      pass: process.env.EMAIL_PASSWORD,
    },
  });
  // Define email option
  const mailOptions = {
    from: 'Jonas Schmedtmann <user@gmail.com>',
    to: options.email,
    subject: options.subject,
    text: options.message,
  };
  // Actually send email
  await transporter.sendMail(mailOptions);
};

module.exports = sendEmail;

// Here we are simply configuring our mail sending mechanism. Here from now we will work on resetting the password.
Uptill now when the user will click on forgot password a user will be validate first after that a token will be generated and its encrypted version will be saved in the database and its unencrypted version will be sent to the email using nodemailer and mailtrap to user. Now the user will go to the reset route with reset token he got in the email and then he send back the token with updated password. Then the password will be compared with the encrypted version saved in the database if it get matched then password will be updated and the reset Token and reset password expires time will be deleted from the database otherwise not.

*****************Resetting the password.

//In authController.js
exports.resetPassword = catchAsnyc(async (req, res, next) => {
  // get user based on token
  const hashedToken = crypto
    .createHash('sha256')
    .update(req.params.token)
    .digest('hex');

  const user = await User.findOne({
    passwordResetToken: hashedToken,
    passwordResetExpires: { $gt: Date.now() },
  });

  //If token hase not expired and there is user set the new password
  if (!user) {
    return next(new AppError('Token is invalid or has expired, 400'));
  }
  //updating password and confirm password
  user.password = req.body.password;
  user.passwordConfirm = req.body.passwordConfirm;

  // deleting the Reset token and reset Token expire from the db once the password is updated
  user.passwordResetToken = undefined;
  user.passwordResetExpires = undefined;

  await user.save(); //here we are not truning OFF the validators. As we want to validate the password.

  //update  changedPasswordAt property for the user
  
  // log the user in, send JWT
  const token = signToken(user._id);
  res.status(200).json({
    status: 'success',
    token: token,
  });
});


//NOTE: here not that we are using save() mehtod to save the data in the database. Here we could also used findOneAndUpdate but we have not done that the reason behind the fact is that all the validators and many middleware runs on save() method thats why we do this.

// In userModel.js
userSchema.pre('save', function (next) {
  if (!this.isModified('password') || this.isNew) return next();

  this.passwordChangedAt = Date.now() - 1000;
  next();
});

**************Allowing a logged in user to update his password who didnt forgot his password

//In authController.js

exports.updatePassword = catchAsnyc(async (req, res, next) => {
  // Get user from collection
  const user = await User.findById(req.user.id).select('+password');
  //here req.user is our current user which we have stored in the above code of protect middleware function

  // Check if the posted current password is correct by comparing it with the password stored in the database
  if (!(await user.correctPassword(req.body.passwordCurrent, user.password))) {
    return next(new AppError('Your current password is wrong!'));
  }
  // If so, update password
  user.password = req.body.password;
  user.passwordConfirm = req.body.passwordConfirm;
  await user.save();

  // Log user in send JWT
  createSendToken(user, 200, res);
});

// here to avoid the repetition of code we have created a separate function for 

// In userRoutes.js

//Rest of the code....
router.patch(
  '/updateMyPassword',
  authController.protect,
  authController.updatePassword,
);


//NOTE: Here we are providing an update password feature for the user who are logged in. The one who will access the updateMyPassword route will be first go through the protect middleware and then updatepassword function where they would be validate too. Once the password is updated the new JWT token will be generated and then send to user.


*********updating current user data other than passsword.

// now we will add function for this purpose in userController.js instead of authController.js

// In userController.js

const filterObj = (obj, ...allowedFields) => {
  const newObj = {};
  Object.keys(obj).forEach((el) => {
    if (allowedFields.includes(el)) newObj[el] = obj[el];
  });
  return newObj;
};

exports.updateMe = catchAsnyc(async (req, res, next) => {
  // 1) Create Error if user POSTs password data
  if (req.body.password || req.body.passwordConfirm) {
    return next(
      new AppError(
        'This route is not for password updates. Please use /updateMyPassword route.',
        400,
      ),
    );
  }

  // 2) Filtered out unwanted fields names that are not allowed to be updated
  const filteredBody = filterObj(req.body, 'name', 'email');
  const updatedUser = await User.findByIdAndUpdate(req.user.id, filteredBody, {
    new: true,
    runValidators: true,
  });

  res.status(200).json({
    status: 'success',
    data: {
      user: updatedUser,
    },
  });
});


//Note: Here we are simply adding a featrue in our app to allow the user to update his data such as email and name. In first part we are preventing the user to post request his password and current password. Then we are restricting our user to not update the whole body includinh role. we are filtering the body which is send by the user and extracting only name and email no matter what user has sent it will only accept name and email and will ignore the rest of the fiels without showing the error. The error will appear only when the user will try to update his password with this route as we have created a separate route for updating the passwords.

// In userRoutes.js

//Rest of the code....
router.patch('/updateMe', authController.protect, userController.updateMe);

//here we are calling the protect middleware which make sure that the user is authenticated and logged In. User must to log in first in order to update his information.


***************Deleting the current user
When we talk about deleting the user we actually do not delete the user from the database we simply mark that account as inactive and hide that user from the database. So that in future the user may rejoin the account.

//In userController.js

//marking the user inactive
exports.deleteMe = catchAsnyc(async (req, res, next) => {
  await User.findByIdAndUpdate(req.user.id, { active: false });

  res.status(200).json({
    status: 'success',
    data: null,
  });
});

//In userModel.js

//add the below field in schema

 active: {
    type: Boolean,
    default: true,
    select: false,
  },

// hiding the user from database
userSchema.pre(/^find/, function (next) {
  //this points to the current query
  this.find({ active: { $ne: false } });
  next();
});
// Here this query middleware will run just before any mongoose method starting with "find" here regex means /^find/ that too.
// this query is like filter. It will only show the users whose active status is not false in the database

// In userRoutes.js
//Rest of the code...
router.delete('/deleteMe', authController.protect, userController.deleteMe);



****************Security Best practices
COMPROMISED DATABASE:
your database should never ever store sensitive data in the form of plain text it must be encrypted.
For example in our case for passwords we have encrypted them using bcrypt and for reset Tokens we have used SHA256 to encyrpt it.

BRUTE FORCE ATTACK:
Brute for attack is a hit and trial attack done by the attacker. In this attack the hacker simply try or loop millions of credentials to access the account.

Preventations:
Use Bcrypt to make the login request slow.
Implement rate limitors such as allowing users to try to login for 10 times for example if a user tried to access his account with wrong credentials 10 times then he will have to wait for 1hr to try login again.


CROSS-SITE-SCRIPTING:
In this attack the hacker tries to run his malicious code on our page. This can be done if user accidentally open some link which is not safe. In this way the hacker will get access to the local storage. Thats the reason we should not store our JWT in local storage. Instead it should be store in Http-cookie only.

Preventations:
Store your JWT in http cookie only instead of local storage. So that browser can send or receive it. Do not access or modify it.
Senitize user data. Do not get data as it is from the user
On backend side to prevent XSS attacks set http special headers so it make harder from the attaker to attack.


DOS (DENIAL OF SERVICE) Attack
In this attack the hacker sends so many attacks to the server that the server got crashed and application becomes unavailable.

Preventations:
Implement rate-limitors. 
Limit the data that can be send in body or post request
Avoid Regular expressions in your code. AS they make you application slower.

NoSQL Query injection
This attack happens when attacker instead of injecting valid data he injects query to create query expressions that are gonna translate to true to get logged in without providing a valid password. For example: we can login to an account without knowing the password. 

preventations:
using mongoose for MongoDB and create a well defined schema
Senitize the user data.


Other Best Practices

In production always always use https not http otherwise your queries and information will be revealed.
Awalys create random password reset token with expiry dates.
Deny access to JWT after the password is changed. The new JWT must be generated and user must have to login in again.
Do not commit config.env file to git.
Do not send error details to the clients like stack trace error otherwise this will leak sensitive information about your files.
To prevent cross site request Forgery use csurf package (Cross-Site Request Forgery (CSRF) is an attack that forces an end user to execute unwanted actions on a web application in which they’re currently authenticated)
Require re-authentication before high value actions such making payments or deleting something.
Implement a blacklist of untrusted tokens. Like we cannot log out the user on they performing malicious activty but we can implement a list of untrusted tokens which must be validate before any query process.
Confirm users email addresses before creating an account
keep user logged in with fresh tokens
Implement two factor authentication. Like after logging in sending an OTP or code to the text or email.


*************sending JWT in httpCookie only
cookie is nothing simply a text that browser used to send and receive to the same server on future requests.

lets add a logic to send jwt in cookie

// In authController.js
const createSendToken = (user, statusCode, res) => {
  const token = signToken(user._id);

  const cookieOptions = {
    expires: new Date(
      Date.now() + process.env.JWT_COOKIE_EXPIRES_IN * 24 * 60 * 60 * 1000,
    ),

    httpOnly: true, //so browser cannot access or modify it
  };

  if (process.env.NODE_ENV === 'production') cookieOptions.secure = true;

  res.cookie('jwt', token, cookieOptions);
  res.status(statusCode).json({
    status: 'success',
    token: token,
    data: {
      user: user,
    },
  });
};

//here we have added our sending cookies function

*********Implementing Rate limiters

we are using a package called 'express-rate-limiter'. To prevent Brute force attacks and denial of service attack etc.

we will implement this logic on top of our app as a global middleware function

// In app.js
const rateLimit = require('express-rate-limit');

const limiter = rateLimit({
  max: 100, //maximum allowed requests
  windowMs: 60 * 60 * 1000, //time in miliseconds
  message: 'Too many requests from this IP, please try again in an hour!',
});

app.use('/api', limiter); // this middleware will be called for routes starting with /api as we know our all routes are starting with /api 


***************Setting security headers
To prevent cross site scripting and XSS attacks:

we are gonna use helmet package to enable security headers
// In app.js

const helmet = require('helmet');
app.use(helmet());

NOTE: Place this middleware on the top of every middleware. so this add headers to all urls and api requests

When you will make http request you will see your node will add some extra security headers which will prevent XSS (cross site scripting) attacks.


***********Data sanitization

// In app.js

const mongoSanitize = require('express-mongo-sanitize');
const xss = require('xss-clean');

// Data sanitization against NoSQL query middleware
app.use(mongoSanitize());

// this above middleware looks for req.body, req.params and req.query strings all dollar signs and dots

// Data sanitization against XSS
app.use(xss());
// this will sanitize the malicious html code


********Preventing Parameter pollution
//In app.js

const hpp = require('hpp');
// Data sanitization against XSS
//Preventing params pollution
app.use(
  hpp({
    whitelist: [
      'duration',
      'ratingsQuantity',
      'ratingsAverage',
      'maxGroupSize',
      'difficulty',
      'price',
    ],
  }),
);


//here if we do a query param such as api/v1/tours?sort=duration&sort=price

here we will get an error as we are passing sort two times as it is our requirement. But this will give an error because of our logic that is in apiFeatures.js
//In apiFeatures.js
const sortBy = this.queryString.sort.split(',').join(' ');

here the split method works only on strings the query param will be an array as ['duration', 'price']

so to fix this we have used hpp module. Only using hpp module will only allow the second method to work such as in this case the sort will be in terms of price. The sort by duration will be ignored as sort is coming twice. But due to hpp module we are at least not getting any error. But there are some cases where we really want twice query of the same property as in this case. So for that case we provide a white list. All properties which are in whiteList will be allowed despite they are twice. 


**************Modeling Data in MongoDB
Here we are gonna study some DBMS stuff.
In real world data apps. Modeling data is one of the most curcial and thought require process.

Real World Scenario --> Unstructured Data --> Structured and logical Model

For example:
There is an online shop we have data of categories, suppliers, carts, customer, orders, products etc. This is an unstructured data. Its structured form would be most likely like this:
categories --> products -->supplier
                  |           |
                  |        Customers
               Orders ---> Carts


There will be four steps that we are gonna follow to model our data
1. Different types of relationships between data
2. Referencing/Noramalization vs. Embedding/Denormalization
3. Embedding or Referencing other docuements?
4. Types of referencing

The way we design or model our data can make or break our application. Lets discuss the above four mentioned points one by one:

1. Different types of relationships between data:

1 : 1 Relation: Movie--> name (One movie can have only one name)
1 : Many: There are three sub types:
	1 : Few: Here a movie can have few awards. A movies cannot have thousands awards. So movie and awards will have 1: few relation.
	1 : Many: Here movie can have thousands of reviews. So movie and review will have 1:Many relation 
	1 : Ton: An App can have ton of logs. here it is hard to differentiate between Many and Ton. You can simply take it as a thing which approaches to infinity can be catergories as `	1:Ton Relation. As an app can have infinite logs. so it is a 1:Ton Relation. The diff. betweej Many and Ton will help us in selecting whether we are supposed to normalize or 	denormalize the data


Many:Many: There are several actors in a movie. On the same side an Actor can work in a several movies. So this would be catergories as Many:Many Relationship


2. Referencing/Noramalization vs. Embedding/Denormalization
In Referecning or Normalization we keep our data separated and well organized. We always add references of chiled object in parent objects object. 
For exmaple:

//Movie Name
{
  "_id": ObjectID('222'),
  "title": "Intersteller",
  "releaseYear": '2014',
  "actors":[
    ObjectID('555'),
    ObjectID('666'),
    ObjectID('777'),

  ]
}
//Actor 1
{
  "_id": ObjectID('555'),
  "name": "Matthew Mc",
  "age": '50',
  "born":"Uvale, USA"
}
//Actor 2
{
  "_id": ObjectID('666'),
  "name": "Andriedue",
  "age": '26',
  "born":"LA, USA"
}
//Actor 3
{
  "_id": ObjectID('777'),
  "name": "Anne Hathaway",
  "age": '37',
  "born":"NYC, USA"
}


//Here Moview Name object is a parent object which conatains all the IDs of actors.
PROS and CONS :
1. Its easier to query each document on its own
2. we need more than one query to get data from the refered object

In Embedding or denoramilzation all the data is embedded in the parent object. It is not separated as above.
For example:
{
  "_id": ObjectID('222'),
  "title": "Intersteller",
  "releaseYear": '2014',
  "actors":[
    //Actor 1
    { 
      "name": "Matthew Mc",
      "age": '50',
      "born":"Uvale, USA"
    },
    //Actor 2
    { 
      "name": "Andriedue",
      "age": '26',
      "born":"LA, USA"
    },
    //Actor 3
    {
      "name": "Anne Hathaway",
      "age": '37',
      "born":"NYC, USA"
    }

  ]
}


// here you can see the actors and movie both are in the same object:

PROS and CONS 
1. Performance: We get all the information in one query.
2. Impossible to query the embedded document on its own.


**************How to decide when to embedd/de-normalize and when to reference/normalize the data?
There are few factors on which we determine whether the data should be normalize or de-normalize. The decision would not be made on the basis of any factor in isolation. The decision would be made in combination.
There is NO HARD RULE to decide in which form the data should be sturctured.

Relationship Type:                 Embedded/De-normaliztion: 1: FEW 		Referencing/Normalization: 1:Many
(How two datasets are 					     1: Many					    1:Ton
related to each other)											    Many:Many

For example:

We have a two dataset: Movies + Images (100) Here it is a 1:Many Relationship. Here since the images are not too much. So therefore, we can simply embed or de-normalize the data.

Data Access Pattern:                 Embedded/De-normaliztion: Data is mostly Read 		Referrencing/Normalization: Data is updated a lot
(How often data is read  				       Data doesn't change quickly			            (low Read/write Ratio)
and write: Read/Write Ratio)				       (High Read/write Ratio)				

For example:

If there is a dataset of Movies + Images then in this case the images and movies are only read there is no way to update the image. So in this case simply embedd the data is suitable. Whereas if there is a dataset of Movies + Reviews then we can normalize/referrencing the data as reviews can be updated a lot. 


Data Closeness:                 Embedded/De-normaliztion: Dataset really belong together 		Referrencing/Normalization: We frequently need to query both datasets on their own.
(How much data is  					     					    
related. How we want											    
to query)

For example:
If there is a datasets of user+ email address then in this case it is suitable to have emails embedded in users object. Whereas if there is a data set such as movies + images then in this case we should go for normalization. As there is case in which user have to tell the name of a movie on the basis of the image shown to him. Then here we are querying two datasets on their own so normalizing/referecing the data would be more suitable. 


NOTE: There is max 16MB limit on Document in mongoDB we cannot exceed this limit. So remember this limitation while modeling your data.

************Types of Referencing/Normalization
Once we have let say decided to Normalize our data then we still have to go through to select one out of three types of referencing.
1. Child Referencing:
{
  "_id": ObjectID('222'),
  "title": "Intersteller",
  "releaseYear": '2014',
  "actors":[
    ObjectID('555'),
    ObjectID('666'),
    ObjectID('777'),

  ]
}
//Actor 1
{
  "_id": ObjectID('555'),
  "name": "Matthew Mc",
  "age": '50',
  "born":"Uvale, USA"
}
//Actor 2
{
  "_id": ObjectID('666'),
  "name": "Andriedue",
  "age": '26',
  "born":"LA, USA"
}
//Actor 3
{
  "_id": ObjectID('777'),
  "name": "Anne Hathaway",
  "age": '37',
  "born":"NYC, USA"
}

// Here this type of referecing is called child Referencing. This type of referencing is only suitable for 1: FEW relationship type. The reason is that as you can see in parent array of Movies the actor array can be long long enough as if there would be so many actors and as we all know in MongoDB each object is count as each document which size should not exceed  16MB. But in case of soo many actors the actors array would be large enough to make the size of this document/obj to exceed 16MB. So therefore, this child refercing is suitable for 1:FEW relationship where its child array have few child elements.

1. Parent Referencing:

//parent
{
  "_id": ObjectID('23'),
  "app": "My Movie Database",

}

//children
{
  "_id": ObjectID('1'),
  "app": ObjectID('23'),
  "type": 'error',
  "timestamp": 23453287432
}

{
  "_id": ObjectID('2'),
  "app": ObjectID('23'),
  "type": 'error',
  "timestamp": 23453287432
}

//Here  you can see every child remember his parent by their IDs but parents have no idea about their children. This case very suitable for 1:Many and 1: Ton relationship type. As there is no fear of exceeding 16MB for each document.

Two-way Referencing:
{
  "_id": ObjectID('23'),
  "title": "Intersteller",
  "releaseYear": '2014',
  "actors":[
    ObjectID('555'),
    ObjectID('666'),
    ObjectID('777'),
    //and many more...

  ]
}

//Actor 1
{
  "_id": ObjectID('555'),
  "name": "Matthew Mc",
  "age": '50',
  "born":"Uvale, USA",
  "movies":[
	ObjectID('23'),
        //and many more
]
}

//Actor 2
{
  "_id": ObjectID('666'),
  "name": "Andriedue",
  "age": '26',
  "born":"LA, USA",
  "movies":[
	ObjectID('23'),
        //and many more
]
}
//Actor 3
{
  "_id": ObjectID('777'),
  "name": "Anne Hathaway",
  "age": '37',
  "born":"NYC, USA",
  "movies":[
	ObjectID('23'),
        //and many more
]
}


// Here in this case both the parents and childs are referecing each other. cause An actor can work in several movies and A movie can have several actors. So this type of referencing is best for many-many relation.


****************Summary*********
1. Sturcture you data the way your application queries and updates data.
2. Identify the question arises from the application use case first and then model your data. So that the questions can get answered in the most efficient way.
3. In general, always favor embedding/De-normalizing, unless there is a good reason for normalizing it. Especially for 1:FEW and 1:Many relationships.
4. A 1:Ton and MANY:MANY relationships are usually the good reason to go for normalizing the data.
5. favor referecning when the data is updated alot and if you need to access a dataset on its own.
6. Use embed/denormalization when the data is mostly read but rarely updated.
7. Do not allow arrays to grow indefinitely. Therefore if you need to normalize, use Child referencing for 1:Few or 1:Many relationship and use Parent referencing for 1:Ton relationships.
8. Use two way referencing for Many:Many Relationship.

*****************Designing Model for Natours app
here in our cases we have 5 data sets
1. Booking
2. Tours
3. Users
4. locations
5. reviews


1. So here users and reviews have 1:Many relation so we are going to use Parent Referencing
2. Tour and user have Many:Many relation so we can either do child referencing or Embedding (Here it would be better to write FEW:FEW instead of MANY:MANY as there will not be many users and tours in our case)
3. Tours and location have also FEW:FEW relation so we will go with Embedding
4. tours and booking have 1:MANY relation we can go with parent referencing here.
5. users and Booking 1:Many here we will also go with parent referencing.



*****************Modeling geoSpatial data
MongoDB also provide a geoSpatial feature to define the locations

Since the location and tour both have close relation so we are model this data in tourModel instead of creating its own collection

//In tourModel.js
// Add the blow fields in your tour Model schema

    startLocation: {
      type: {
        type: String,
        default: 'Point',
        enum: ['Point'],
      },
      coordinate: [Number], // here we will get longitude and latitude of the points
      address: String,
      description: String,
    },
    location: [
      {
        type: {
          type: String,
          default: 'Point',
          enum: ['Point'],
        },
        coordinate: [Number], // here we will get longitude and latitude of the points
        address: String,
        description: String,
        day: Number,
      },
    ],

// Now once we have updated our model we have to delete the all pervious data and upload this new one. 
For that go to your script that we had created to load and delete data from our DB

node ./dev-data/data/import-dev-data.js --delete
node ./dev-data/data/import-dev-data.js --import

By running above two commands you have deleted the old and uploaded the new data in you tour Model.


**************Embedding/Denormalizing user Data in tour model
Actually we are adding the guides from user and embedding it into the tour model.

The logic is simple when a user will create a new tour he will pass the ids of the guides in the guides array and then in tour schema a document middleware will be called before saving the document that middlware will find the guides in the user model and will embed them in tour model
// In tourModel.js
const User = require('./../models/userModel');

// add a guides field in tour model of array type:
//Rest of the model...

guides: Array,

tourSchema.pre('save', async function (next) {
  const guidesPromises = this.guides.map(async (id) => await User.findById(id));
  this.guides = await Promise.all(guidesPromises); // dealing with all promises which are stored in guidesPromises due to looping 
  next();
});



//Postman:
//In put raw JSON Body
{
    "name": "The new Test Tour",
    "duration": 1,
    "maxGroupSize": 1,
    "difficulty": "difficult",
    "price": 1,
    "summary": "Test tour",
    "imageCover": "tour-3-cover.jpg",
    "guides" :[
        "6540853b94306261841c04bb",
        "653cfb3337108a552484beaa"
    ]
  
}


// This is how we implement embedding another document in other document.
// Remember we have embedded/de-normalized data in this case not referenced/normalized


****************Referencing/normalizing user data into tour model

In the above code we compelely embedded the user data into the tour model but now we are gonna making the reference of user data. Means instead of directly putting the whole user objects on the basis of their id in the tour model. we will add object Ids only which will refer to the User data.

So comment the above code and replace it with the below:

//In tourModel.js
// make the below changes in guides field in tourModel.js

guides: [
      {
        type: mongoose.Schema.ObjectId,
        ref: 'User',
      },
],



//Postman:
//In put raw JSON Body
{
    "name": "The new Test Tour",
    "duration": 1,
    "maxGroupSize": 1,
    "difficulty": "difficult",
    "price": 1,
    "summary": "Test tour",
    "imageCover": "tour-3-cover.jpg",
    "guides" :[
        "6540853b94306261841c04bb",
        "653cfb3337108a552484beaa"
    ]
  
}


// Now our output result will contain only the object ID not the whole object. The user data is still in a separate collection it is not embedded in tour model.

**********Now we are gonna populate the user data in tour Document

Actually here populating simple means filling. The result of this populating would be same as embedding the data but the in embedding we were embedding the data into the tourModel. In this case were we have referred our object we will see the data is showing in the tour model. But in actual the data is still in the User document separately.

Implementation of populating is simple. Just take is a virtual representation of data instead of just showing Referenced ID in the model.

This can be done by using query middleware. Because the populate function actually makes a query of to find the object by Id and then shows them in the model.

//In tourModel.js

tourSchema.pre(/^find/, function (next) {
  this.populate({
    path: 'guides',
    select: '-__v -passwordChangedAt',
  });
  // here its trick to unselect the object which we do not want to show or you can say we want to hide.

  next();
});

// This is how we implement populate and referencing. Now we will see the objects data in our tour collection. whereas the user data is still in the separate collection.

*************Modeling reviews Parent referencing
//create a new js file in Models folder called reviewModel.js

//In reviewModel.js
const mongoose = require('mongoose');

const reviewSchema = new mongoose.Schema(
  {
    review: {
      type: String,
      required: [true, 'Review cannot be empty'],
    },
    rating: {
      type: Number,
      min: 1,
      max: 5,
    },
    createdAt: {
      type: Date,
      default: Date.now(),
    },
    tour: {
      type: mongoose.Schema.ObjectId,
      ref: 'Tour',
      required: [true, 'Review must belong to a tour.'],
    },

    user: {
      type: mongoose.Schema.ObjectId,
      ref: 'User',
      require: [true, 'Review must belong to a user.'],
    },
  },
  {
    toJSON: { virtuals: true },
    toObject: { virtuals: false },
  },
);

const Review = mongoose.model('Review', reviewSchema);
module.exports = Review;



***************Creating and getting reviews
// Create reviewCOntroller.js in controller folder

// In reviewController.js
const Review = require('./../models/reviewModel.js');
const catchAsync = require('./../utils/catchAsync');

exports.getAllReviews = catchAsync(async (req, res) => {
  const reviews = await Review.find();
  res.status(200).json({
    status: 'success',
    results: reviews.length,
    data: {
      reviews: reviews,
    },
  });
});
exports.createReview = catchAsync(async (req, res) => {
  const newReview = await Review.create(req.body);

  res.status(201).json({
    status: 'success',
    data: {
      review: newReview,
    },
  });
});


// Create reviewRoutes.js in routes folder

const express = require('express');

const reviewController = require('./../controllers/reviewContoller');

const authController = require('./../controllers/authController');

const router = express.Router();

router
  .route('/')
  .get(reviewController.getAllReviews)
  .post(
    authController.protect,
    authController.restrictTo('user'),
    reviewController.createReview,
  );

module.exports = router;


//In app.js
//add the following code

const reviewRouter = require('./routes/reviewRoutes');
app.use('/api/v1/reviews', reviewRouter);



//In postman
POST request {{URL}}api/v1/reviews/

creating review
{
    "review":"loved it!",
    "rating":"5",
    "tour":"5c88fa8cf4afda39709c2955",
    "user":"65446749ac36f14710cf8db8"
}


***********Populating reviews
// In reviewModel.js

//populating user and tour
reviewSchema.pre(/^find/, function (next) {
  this.populate({
    path: 'tour',
    select: 'name',
  }).populate({
    path: 'user',
    select: 'name Photo',
  });

  next();
});


***************Virtually populating reviews and tours
Here despite populating the reviews we have one problem unsolved that is the problem. The problem is that when we query for the reviews we will get see the tours data. But on querying for tours will not give us the data for reviews. As in this case reviews are pointing toward tours but tours are not pointing toward reviews. Since we have done parent referenceing, In parent referencing parent does not know about its children. Similarly in this case tours (parents) does not know about its children (reviews).

There are two solution for this problem.
1. Either we do query manually for reviews when we do query for tours. But this solution is not acceptable.
2. Do child referencing in tour model or populate an array in tours model. This solution is not feasible as we know the rule. The array should not be exceed 16MB or not too large as we know the user will adding reviews for tours which make the review array could be go infinitely large which we cannot afford in embedding the array.


So the most feasible solution is probvided by mongoose. That is virtual Populate. 

//In tourModel.js
//Virtual populate
tourSchema.virtual('reviews', {
  ref: 'Review',
  //Now connecting two models.
  foreignField: 'tour', //here we specify the field to connet. In reviewModel we have tour field where the id of tour is being stored.
  localField: '_id', //here the _id which is id in the current model will be called tour in Foreign Model that is reviewModel.
});

NOTE: Since we only want to show review with tours when the user make request to see a specific tour not on all tours as it would be a lot of information that user will get. 
So to do that go to you tourController and getTour function

//In tourController.js

Replace this line "const tour = await Tour.findById(req.params.id)"
with "const tour = await Tour.findById(req.params.id).populate('reviews');"

//IMPORTANT

Now on querying the result you will your reviews has been successfully populated in tours. But the problem will you notice is that the populating will have become nested. As there will be tour having a field of reviews which contains again the information of the tour and user which is unnecessary and already defined in tour.
So to avoid this go to reviewModel.js

//In reviewModel.js

In your poplulating query middeware

replace 

  this.populate({
      path: 'tour',
      select: 'name',
    }).populate({
      path: 'user',
      select: 'name Photo',
    });

with

  this.populate({
      path: 'user',
      select: 'name Photo',
    });


**********Nested route
here in this concept we will implement the nested routes.
Actually when a user make a review the user have to enter his ID and the id of the tour of which he want to create a review. This is acceptable only for development purposes but in case of production this wont be the case.

The case would be like that we have to create a separete nested route which contains the id of the tour 

POST tour/s32r843hci934hf94380f/review

here s32r843hci934hf94380f this is the random ID of a tour of which we want to create review

//In tourRoutes.js
// add the following route

router
  .route('/:tourId/reviews')
  .post(
    authController.protect,
    authController.restrictTo('user'),
    reviewController.createReview,
  );


now go to createReview function

and replace that function with the following logic

// In reviewController.js
exports.createReview = catchAsync(async (req, res) => {
  //Allowing nested routes
  // since we are not providing our tour Id and user Id in the req.body object instead we are providing them in the URL. So below we are getting that data from URL  so that we do not have     // to enter it manually
  if (!req.body.tour) req.body.tour = req.params.tourId;
  if (!req.body.user) req.body.user = req.params.id;

  const newReview = await Review.create(req.body);

  res.status(201).json({
    status: 'success',
    data: {
      review: newReview,
    },
  });
});


// In postman
POST {{URL}}api/v1/tours/5c88fa8cf4afda39709c2955/reviews

body:

{
    "rating":5,
    "review":"Best tour in the world!"
}



************Merger params
In the above code there is an issue that problem is that you may have noticed that we are using create review route in tour Routes which is agianst the rule and can be quite confusion. we did this just because the route is starting with tour? Still this is not feasible. 
to deal with this situation we are gonna use merge params. This will redirect our route.
In simple words it logic work like that "If you found a route like "/:tourId/reviews/" redirect it to reviewRoutes

Lets implement this made changes in the above code
keep all things same except 
the below code in tourRoutes.js 

//In tourRoutes.js

remove this code
  .route('/:tourId/reviews')
  .post(
    authController.protect,
    authController.restrictTo('user'),
    reviewController.createReview,
  );


and add:

const reviewRoutes = require('./../routes/reviewRoutes');
router.use('/:tourId/reviews', reviewRoutes);
//Here whenever the user will come to /tour route and found a route like this "/:tourId/reviews/" this middleware will redirect it to reviewRoutes"

//In reviewRoutes.js
add this line of code.

const router = express.Router({ mergeParams: true });

mergeParams will help use to get access to id which is in the URL

// In postman
POST {{URL}}api/v1/tours/5c88fa8cf4afda39709c2955/reviews

body:

{
    "rating":5,
    "review":"Best tour in the world!"
}


********Making Nested get tour
Now we are gonna implement same mechanism for getting the review on the basis of id of the tour in the URL

simply go to reviewController.js

//In reviewController.js

Modify your reviewController as 

exports.getAllReviews = catchAsync(async (req, res) => {
  let filter = {};
  //here we are looking for tourId in url
  if (req.params.tourId) filter = { tour: req.params.tourId };
  const reviews = await Review.find(filter);
  res.status(200).json({
    status: 'success',
    results: reviews.length,
    data: {
      reviews: reviews,
    },
  });
});


now due to the above implemented mergeParams this function will be called on making GET request
// In postman
POST {{URL}}api/v1/tours/5c88fa8cf4afda39709c2955/reviews

*************Factory function for deleting Single user, review and tour

There is nothing new we are simply refracting our code to not repeat it.

simply create a file namely "handlerFactory.js" in controller folder

//In handlerFactory.js
const catchAsnyc = require('./../utils/catchAsync');
const AppError = require('./../utils/appError');

// Here we are making a generic function to delete one item
exports.deleteOne = (Model) =>
  catchAsnyc(async (req, res, next) => {
    const doc = await Model.findByIdAndRemove(req.params.id);
    if (!doc) {
      return next(new AppError('No Tour Found with this ID', 404));
    }
    res.status(204).json({
      status: 'success',
      data: null,
    });
  });


// Here we just have to import this generic function where we want and we simply have to pass our respective model.

So now go to your respective controller files where you want to use this function

// In tourController.js
const factory = require('./handlerFactory');
exports.deleteTour = factory.deleteOne(Tour);

//simple is that 



// In userController.js
const factory = require('./handlerFactory');
exports.deleteUser = factory.deleteOne(User);

// In reviewController.js
const factory = require('./handlerFactory');
exports.deleteReview = factory.deleteOne(Review);


// Here the logic is that when ever the user will hit respective route these functions would be called and these functions would call handlerFactory function.


****************Creating factory handler function for update and create user, tour and review
//In handlerFactory.js

// Here we are making a generic function to create one item
exports.createOne = (Model) =>
  catchAsnyc(async (req, res, next) => {
    const doc = await Model.create(req.body);
    res.status(200).json({
      status: 'success',
      data: {
        data: doc,
      },
    });
  });


**NOTE**: Make sure that all your functions in handlerFactory function must return a function otherwise they would be considered as an empty object. Therefore in the above callback function I am not using any bracktes after => arrow so that arrow function automatically return it. In case of { } one must have to use return statement. otherwise they would be considered as an empty object.


// In tourController.js
const factory = require('./handlerFactory');
exports.createTour = factory.createOne(Tour);
exports.updateTour = factory.updateOne(Tour);

//In reviewController.js
const factory = require('./handlerFactory');

//here we have created a middleware:
exports.setTourUserIds = (req, res, next) => {
  //Allowing nested routes
  // since we are not providing our data in the body object we will provide them in the URL.
  if (!req.body.tour) req.body.tour = req.params.tourId;
  if (!req.body.user) req.body.user = req.params.id;
  next();
};

exports.createReview = factory.createOne(Review);
exports.updateReview = factory.updateOne(Review);

// since we have introduced a middleware here. Lets add it in the stack in reviewRouter.js
router
  .route('/')
  .get(reviewController.getAllReviews)
  .post(
    authController.protect,
    authController.restrictTo('user'),
    reviewController.setTourUserIds, //here is the middleware
    reviewController.createReview,
  );

// In userController.js
const factory = require('./handlerFactory');
//Do not try to update password with this update function!
exports.updateUser = factory.updateOne(User);

// there is no need to do createOne for user. As there is a separate for creating user that is signup route.


************Factory Function for getOne and getAll reviews, users and tours

// In handlerFactory.js
exports.getOne = (Model, popOptions) =>
  catchAsnyc(async (req, res, next) => {
    let query = Model.findById(req.params.id);
    if (popOptions) query = query.populate(popOptions);
    const doc = await query;
    if (!doc) {
      return next(new AppError('No document Found with this ID', 404));
    }
    res.status(200).json({
      status: 'success',
      data: {
        data: doc,
      },
    });
  });

exports.getAll = (Model) =>
  catchAsnyc(async (req, res, next) => {
    //To allow for nested GET reviews on tour (hack)
    let filter = {};
    //here we are looking for tourId in url
    if (req.params.tourId) filter = { tour: req.params.tourId };
    // EXECUTE QUERY
    const features = new APIFeatures(Model.find(filter), req.query)
      .filter()
      .sort()
      .limitFields()
      .paginate();
    const doc = await features.query;

    res.status(200).json({
      status: 'success',
      results: doc.length,
      data: {
        data: doc,
      },
    });
  });


// In tourController.js
const factory = require('./handlerFactory');
exports.getAllTours = factory.getAll(Tour);
exports.getTour = factory.getOne(Tour, { path: 'reviews' });

// In reviewController.js
const factory = require('./handlerFactory');
exports.getAllReviews = factory.getAll(Review);
exports.getReview = factory.getOne(Review);

//In userController.js
const factory = require('./handlerFactory');
exports.getAllUsers = factory.getAll(User);
exports.getUser = factory.createOne(User);


***********Adding me End point to get the current user data
//In userController.js
exports.getMe = (req, res, next) => {
  req.params.id = req.user.id;
  next();
};

// here we have created a middleware...actually we will get the data from our factory function that is getOne(User) but the problem is that the getUSer function requires an id of the user but here in /me route we do not want to pass any id we simply want to get the data of the current logged in user if the user is logged in.
So here we are assigning the req.params.id variable that is gonna use in getUser function equal to req.user.id which is the id of the current logged in user.

// In userRoutes.js
router.get(
  '/me',
  authController.protect,
  userController.getMe,
  userController.getUser,
);


*************Adding missing authentications and autherizations
// In tourRoutes.js
const express = require('express');

const tourController = require('../controllers/tourController');
const authController = require('../controllers/authController');
const reviewRoutes = require('./../routes/reviewRoutes');

const router = express.Router();
router.use('/:tourId/reviews', reviewRoutes);
router
  .route('/top-5-cheap')
  .get(tourController.aliasTopTours, tourController.getAllTours);

router.route('/tour-stats').get(tourController.getTourStats);
router
  .route('/monthly-plan/:year')
  .get(
    authController.restrictTo('admin', 'lead-guide', 'guide'),
    tourController.updateTour,
    tourController.getMonthlyPlane,
  );
router
  .route('/')
  .get(tourController.getAllTours)
  .post(
    authController.protect,
    authController.restrictTo('admin', 'lead-guide'),
    tourController.createTour,
  );
router
  .route('/:id')
  .get(tourController.getTour)
  .patch(
    authController.protect,
    authController.restrictTo('admin', 'lead-guide'),
    tourController.updateTour,
  )
  .delete(
    authController.protect,
    authController.restrictTo('admin', 'lead-guide'),
    tourController.deleteTour,
  );

module.exports = router;


// In userRoutes.js

const express = require('express');
const userController = require('../controllers/userController');
const authController = require('../controllers/authController');

const router = express.Router();
router.post('/signup', authController.signup);
router.post('/login', authController.login);
router.post('/forgotPassword', authController.forgotPassword);
router.patch('/resetPassword/:token', authController.resetPassword);

router.use(authController.protect);
// all routes after this middleware are protected as we know middleware runs in sequence.
// so all routes below this will be reached only when the above middlware will approve them as an authenticated user. SO there is no need to individually add the protect function in each route separately.

router.patch('/updateMyPassword', authController.updatePassword);
router.get('/me', userController.getMe, userController.getUser);
router.patch('/updateMe', userController.updateMe);
router.delete('/deleteMe', userController.deleteMe);

router
  .route('/')
  .get(userController.getAllUsers)
  .post(userController.createUser);
router
  .route('/:id')
  .get(userController.getUser)
  .patch(userController.updateUser)
  .delete(userController.deleteUser);

module.exports = router;

// In reviewRoutes.js
const express = require('express');

const reviewController = require('./../controllers/reviewContoller');

const authController = require('./../controllers/authController');

const router = express.Router({ mergeParams: true });

router
  .route('/')
  .get(reviewController.getAllReviews)
  .post(
    authController.protect,
    authController.restrictTo('user'),
    reviewController.setTourUserIds,
    reviewController.createReview,
  );

router
  .route('/:id')
  .get(reviewController.getReview)
  .patch(
    authController.restrictTo('user', 'admin'),
    reviewController.updateReview,
  )
  .delete(
    authController.restrictTo('user', 'admin'),
    reviewController.deleteReview,
  );

module.exports = router;

*************Importing Tours, users and reviews data

// In dev-import-data.js
const fs = require('fs');
const mongoose = require('mongoose');
const dotenv = require('dotenv');

const Tour = require('./../../models/tourModel'); // Importing out model/collection
const User = require('./../../models/userModel'); // Importing out model/collection
const Review = require('./../../models/reviewModel'); // Importing out model/collection

dotenv.config({ path: './config.env' });

const DB = process.env.DATABASE.replace(
  '<PASSWORD>',
  process.env.DATABASE_PASSWORD,
);
mongoose
  .connect(DB, {
    useNewUrlParser: true,
    useCreateIndex: true,
    useFindAndModify: false,
    useUnifiedTopology: true,
  })
  // eslint-disable-next-line no-console
  .then(() => console.log('Database Connected Successfully'));

// Readung json file
const tours = JSON.parse(fs.readFileSync(`${__dirname}/tours.json`, 'utf-8'));
const users = JSON.parse(fs.readFileSync(`${__dirname}/users.json`, 'utf-8'));
const reviews = JSON.parse(
  fs.readFileSync(`${__dirname}/reviews.json`, 'utf-8'),
);
/* parse() JSON parsing is the process of converting a JSON object which is in text format to a Javascript object
 that can be used inside a program*/

// importing data into DB
const importData = async () => {
  try {
    await Tour.create(tours);
    await User.create(users, { validateBeforeSave: false });
    await Review.create(reviews);
    console.log('Data successfully loaded!');
  } catch (err) {
    console.log(err);
  }
  process.exit();
};

// Deleting already present data in database
const deleteData = async () => {
  try {
    await Tour.deleteMany(); //we will pass nothing so it will delete all the data
    await User.deleteMany(); //we will pass nothing so it will delete all the data
    await Review.deleteMany(); //we will pass nothing so it will delete all the data
    console.log('All previous data have deleted successfully');
  } catch (err) {
    console.log(err);
  }
  process.exit();
};

// Process.argv
if (process.argv[2] === '--import') {
  importData();
} else if (process.argv[2] === '--delete') {
  deleteData();
}
console.log(process.argv);

//***Command in the terminal
node ./dev-data/data/import-dev-data.js --delete
node ./dev-data/data/import-dev-data.js --import


***************Increasing the reading performance
Whenever a user do a query over fields to get some specified results then the database have to go through all fields to find that specific one. For example for our query
GET {{URL}}api/v1/tours?price[lt]=20&averageRating[gt]=4.7

and we get only 3 results out of 100 fields.

if you would apply explain() method on your query function in your code then you will see how many documents were examined and out of that how much get that returns. In case of thousands of documents this will make our reading process slow. As to get only 3 results the database has to look or scan over thousands of documents. So to solve this problem indexes come here.

All you have to do is to specify indexes on specific fields. How would you get to know on which field you have to do indexing? The answer is that you have to study or analyze the user most search field as here in our case it is slug, price and averageRating comparison.

there are two types of indexing, 
1. Unique
2. Compound

By indexing the database directly look for index instead of scanning the whole document. Which in results increases the performance. But remember, indexes also come at some cost that is their size. The size of a single index is greater than the size of a document. So we carefully have to apply index on only those fields which are  most in use. Do not blindly apply indexing. First analyze your data and then apply indexing.

//In tourModel.js
// Rest of the code...
// setting index to increase reading data performance

tourSchema.index({ price: 1, ratingsAverage: -1 }); //compound
tourSchema.index({ slug: 1 }); //unique


***************calculaitng ratings Average using aggregation pipeline and static method
This static method will be called each time when the user rate a tour. This function will add the new rating and then calculate the new updated average rating and will store it in the database.

// In reviewModel.js
reviewSchema.statics.calcAverageRatings = async function (tourId) {
  // here we will make aggregation pipeline
  const stats = await this.aggregate([
    {
      $match: { tour: tourId },
    },
    {
      $group: {
        _id: '$tour',
        nRating: { $sum: 1 },
        avgRating: { $avg: '$rating' },
      },
    },
  ]);

  console.log('stats: ', stats);

  await Tour.findByIdAndUpdate(tourId, {
    ratingsQuantity: stats[0].nRating,
    ratingsAverage: stats[0].avgRating,
  });
};

reviewSchema.post('save', function () {
  // this points to current review
  this.constructor.calcAverageRatings(this.tour);
  //here this.construtor points toward Review Model
});

// here we are applying static method as it is very handy for applying aggregation pipeline. First we are selecting all the reviews on the current tourId and then we are applying sum and average on them.
to call this we are using post method. 

**NOTE**: I got an error called model cannot be overwrite to prevent this I added a line of in tourMode.js
mongoose.models = {};
//add this code before the below line
const Tour = mongoose.model('Tour', tourSchema);

************Updating review statistics on updating and deleting the review
when a user updates or delete a review total number of reviews or average rating should be changed. To note this change and update review statistics we do not have any specific data

//findByIdAndUpdate
//findByIdAndDelete

reviewSchema.pre(/^findOneAnd/, async function (next) {
  this.r = await this.findOne(); //executing the query to get review document here r stands for review,
  // saving the data in this.r this is a trick to pass data from pre middleware to post middleware
  next();
});
reviewSchema.post(/^findOneAnd/, async function () {
  // await this.findOne(); THIS will not work here as query has already executed.
  await this.r.constructor.calcAverageRatings(this.r.tour); //here this.r is from the above pre middleware
});

//here we will user query middleware....The pre middlware is used just to get the review document. In second step of post we are here calling calcAverageRatings to calculate the statistics again

***********preventing duplicate reviews
here we will prevent the same user to make duplicate reviews
we can do with this by using compound index

// go to reviewModel.js

reviewSchema.index(
  { tour: 1, user: 1 }, // here we are compounding
  {
    unique: true, //here we are setting to it unique so that on making its duplicate it give error
  },
);

************Implementing geoSpatial Queries to find the tours within the provided radius

The logic is simple using geospatial queries we will provide a coordinates and radius of the region then the mongoose will run the search uisng find method and will filter the tours which are within the provided range of radius.

// In tourRoutes.js
//REST of the code....
router
  .route('/tours-within/:distance/center/:latlng/unit/:unit')
  .get(tourController.getToursWithin);
// /tours-within?distance=223&center=-40,45&unit=mi
// /tours-within/223/center/40,45/unit/mi

// In tourContoller.js
exports.getToursWithin = catchAsnyc(async (req, res, next) => {
  const { distance, latlng, unit } = req.params;
  const [lat, lng] = latlng.split(',');

  const radius = unit === 'mi' ? distance / 3963.2 : distance / 6378.1;
  // here 3963.2 and 6378.1 is radius of earth in miles and kilometers respectively

  if (!lat || !lng) {
    next(
      new AppError(
        'Please provide latitutr and longitude in the format lat,lng.',
        400,
      ),
    );
  }

  const tours = await Tour.find({
    startLocation: { $geoWithin: { $centerSphere: [[lng, lat], radius] } },
  });

  res.status(200).json({
    status: 'success',
    results: tours.length,
    data: {
      data: tours,
    },
  });
});

//In tourModel.js
//Rest of the code
tourSchema.index({ startLocation: '2dsphere' }); // 2D in index for geospatial properties
//We did this cause $geoWithin requires an a 2dSphere index to execute the query and this index will help us to find or match the results.

//In POSTMAN
GET {{URL}}api/v1/tours/tours-within/200/center/34.111745,-118.113491/unit/mi

*****************Using geoSpatial aggregation to calculate the distance from the provided coordinates
// In tourRoutes.js

router.route('/distances/:latlng/unit/:unit').get(tourController.getDistances);

//In tourController.js
exports.getDistances = catchAsnyc(async (req, res, next) => {
  const { latlng, unit } = req.params;
  const [lat, lng] = latlng.split(',');
  const mulitplier = unit === 'mi' ? 0.000621371 : 0.001;

  if (!lat || !lng) {
    next(
      new AppError(
        'Please provide latitutr and longitude in the format lat,lng.',
        400,
      ),
    );
  }

  const distances = await Tour.aggregate([
    {
      $geoNear: {
        near: {
          type: 'Point',
          coordinates: [lng * 1, lat * 1],
        },
        distanceField: 'distance',
        distanceMultiplier: mulitplier,
      },
    },
    {
      $project: {
        distance: 1,
        name: 1,
      },
    },
  ]);
  res.status(200).json({
    status: 'success',
    data: {
      data: distances,
    },
  });
});

// IN tourModel.js
// tourSchema.pre('aggregate', function (next) {
//   this.pipeline().unshift({ $match: { secretTour: { $ne: true } } });
//   console.log('aggregation middleware pipeline: ', this.pipeline());

//   next();
// });

comment our the above code in tourModel.js
the reason is that the $geoNear field should be the first one in aggration pipeline otherwise you will get an error. And this above code which I have recommended you to comment out is making $geoNear a second field by maiking $match field the first one.

//also geoNear requires an index in the model so below is that:

//In tourModel.js
//Rest of the code
tourSchema.index({ startLocation: '2dsphere' }); // 2D in index for geospatial properties
//We did this cause $geoWithin & $geoNear requires an a 2dSphere index to execute the query and this index will help us to find or match the results.

//PostMan
GET {{URL}}api/v1/tours/distances/34.111745,-118.113491/unit/mi

********************Documentation
Go to postman and add documentation.
set variable for password



******************API section Completed Here


************Extra

//In config folder (backend)
//In allowedOrigin.js
const allowedOrigins = [
    'https://www.yoursite.com',
    'http://127.0.0.1:5500',
    'http://localhost:3500',
    'http://localhost:3000'
];

module.exports = allowedOrigins;


//In corsOptions.js
const allowedOrigins = require('./allowedOrigins');

const corsOptions = {
    origin: (origin, callback) => {
        if (allowedOrigins.indexOf(origin) !== -1 || !origin) {
            callback(null, true)
        } else {
            callback(new Error('Not allowed by CORS'));
        }
    },
    optionsSuccessStatus: 200
}

module.exports = corsOptions;

//In dbConn.js
const mongoose = require('mongoose');

const connectDB = async () => {
    try {
        await mongoose.connect(process.env.DATABASE_URI, {
            useUnifiedTopology: true,
            useNewUrlParser: true
        });
    } catch (err) {
        console.error(err);
    }
}

module.exports = connectDB

//roles_list
const ROLES_LIST = {
    "Admin": 5150,
    "Editor": 1984,
    "User": 2001
}

module.exports = ROLES_LIST

******************Refresh token concept
There is also an advance concept called refresh token. The concept is simple. Let say you have logged in on ABC.com you get access token with an expiry time of 10min. After 10min your access token will be expired. Now user have to login again. In this case the backend will send an error to frontend with a status code of either 401 or 403. So handling this error and not to make user log in again without entering his credentials again. The backend right away sends a refresh token to the client and then the client sends back this refresh token to the server showing that he is a valid user and then again backend varifies that refresh token as backend contains a secret_refresh_Token in its .env file and will generate a new access token which will remain valid for next 10 min and will send to the frontend. Now front will store the new token in its cookies and will use it for the future concept. In this way you can make your app more secure by generating new token after every session. Remember the refresh token is generated and a new token is assigned on a specific route not on all routes.
In backend we use middlewares to create the pipeline and in frontend we use interceptors to create this pipeline to automate this whole process.
Always remember there is a separat route for generating a refresh token e.g /refresh on making request to this route will give you refresh token.
This all process will be happening in the background. User won't know whats happening in the background. Always remember your refresh token have longer expiry time than accessToken. During the time your refresh token is valid you will be allowed to generate accesstoken on every expiry of accessToken. Once the refresh token has expired you will have to login again.


*********************Uploading files using Multer
//Here we have to show both front end and backend as well. So for front end Im using React.

//Front End
import React, { useState } from "react"
import axios from 'axios'

function App() {
  const [file, setFile] = useState()
  const upload = () => {
    const formData = new FormData()
    formData.append('file', file)
    axios.post('http://localhost:3001/upload',formData )
    .then( res => {})
    .catch(er => console.log(er))
  }
   return (
    <div>
      <input type="file" onChange={(e) => setFile(e.target.files[0])}/>
      <button type="button" onClick={upload}>Upload</button>
    </div>
  )
}

export default App;

//here we doing nothing, simply creating an input field which will store the uploading file in file variable using useState hook. Then we are creating a button which will call an upload function on click. Here in upload function we are simple storing our file in the form of an object and sending it to the backend using http post method on /upload endpoint.


//Back End
const express = require('express')
const cors = require('cors')
const multer = require('multer')

const app = express()
app.use(cors())
app.use(express.json())

const storage = multer.diskStorage({
  destination: function(req, file, cb) {
    return cb(null, "./public/Images")
  },
  filename: function (req, file, cb) {
    return cb(null, `${Date.now()}_${file.originalname}`)
  }
})

const upload = multer({storage})

app.post('/upload', upload.single('file'), (req, res) => {
  console.log(req.body)
  console.log(req.file)
})

app.listen(3001, () => {
  console.log("Server is running")
})


//here we have simply created a server which is listening on port 3001. The main thing here is multer() function which requires a storage object. Here storage object contains two thing one is destination and other is filename. Providing all that. We are creating our endpoint to get the data coming from the user. here in upload.single() the single() method is basically applying on multer function. Single is for uploading the single file. For multiple files you can use arrays. you can also integrate your database as req.body contains that file which user is sending from the front end. You can store it in your database.

NOTE: There is another npm package called cloudinary. You can also use that app to upload media.


*******************Payment methods (thoery)
Whenever we make online payments we do not pay directly to the website or product owner. For example you have bought a product from amazon and you did an online payment. Here on making a successful payment your amount will be sent to the Payment gateway (e.g strip etc.) These payment gateways send a token to the product owner and then the product has released. The question here is that when the actual owner would get the payment? The answer is that he will have to negotiate with the payment gateway. They may either pay him after 3 days or maybe 30 days it depends on your deal which you have done so far.

Some popular gateways:
Braintree
Stripe
Razorpay
Instamojo
EBS
2checkout

**States of Online Payment
1) Failed: 
When a payment get failed, which is totally fine. User, Payment gateways, banks all get the payment failed notification ensuring that we all are on the same page. The reason of failure can be incorrect card number, incorrect name, insufficient balance, incorrect OTP entered, payment not completed on time etc.

2) Captured/ Success:
Simply payment has done successfully. Everyone is happy. There is huge process behind this successfull payment. 

3) Authorized:
The Authorization is not equal to success but its an important part of the whole process.

                                                            |------------> Payment Created -------->|
                                                            |------------> Payment Failed --------->|
                                                            |                                       |
Customer Attempts payment ---> Bank sends status ---> Payment Gateway ---> Authorized------->Late Autorized
                                                                             |                      |
                                                                             |--->Success/Refund<---|

NOTE: Your payment is always safe. If the payment is not authorized then the default of the gateway is to send back or refund the payment to the users account usually after 3 to 4 days.
Late Authorized
Refunds


